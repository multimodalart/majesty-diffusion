{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/multimodalart/majesty-diffusion/blob/main/latent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUmmV5ZvrPbP"
      },
      "source": [
        "# Latent Majesty Diffusion v1.3\n",
        "#### Formerly known as Princess Generator\n",
        "##### Access our [Majestic Guide](https://multimodal.art/majesty-diffusion) (_under construction_), our [GitHub](https://github.com/multimodalart/majesty-diffusion), join our community on [Discord](https://discord.gg/yNBtQBEDfZ) or reach out via [@multimodalart on Twitter](https://twitter.com/multimodalart))\n",
        "\\\n",
        " \n",
        "---\n",
        "\\\n",
        "\n",
        "\n",
        "#### CLIP Guided Latent Diffusion by [dango233](https://github.com/Dango233/) and [apolinario (@multimodalart)](https://twitter.com/multimodalart). \n",
        "The LAION-400M-trained model and the modified inference code are from [CompVis Latent Diffusion](https://github.com/CompVis/latent-diffusion). The guided-diffusion method is modified by Dango233 based on [Katherine Crowson](https://twitter.com/RiversHaveWings)'s guided diffusion notebook. multimodalart savable settings, MMC and assembled the Colab. Check the complete list on our GitHub. Some functions and methods are from various code masters (nsheppard, DanielRussRuss and others)\n",
        "\n",
        "Changelog: 1.3 - better upscaler (learn how to use it on our [Majestic Guide](https://multimodal.art/majesty-diffusion))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWLsDt7wkZfU"
      },
      "source": [
        "## Save model and outputs on Google Drive? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "aJF6wP2zkWE_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model will be stored at /home/jon/notebooks/majesty-diffusion/models\n",
            "Outputs will be saved to /home/jon/notebooks/majesty-diffusion/outputs\n"
          ]
        }
      ],
      "source": [
        "#@markdown Enable saving outputs to Google Drive to save your creations at AI/models\n",
        "save_outputs_to_google_drive = False #@param {type:\"boolean\"}\n",
        "#@markdown Enable saving models to Google Drive to avoid downloading the model every Colab instance\n",
        "save_models_to_google_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "if save_outputs_to_google_drive or save_models_to_google_drive:\n",
        "    from google.colab import drive\n",
        "    try:\n",
        "      drive.mount('/content/gdrive')\n",
        "      model_path = \"/content/gdrive/MyDrive/AI/models\" if save_models_to_google_drive else \"/content/\"\n",
        "      outputs_path = \"/content/gdrive/MyDrive/AI/latent_majesty_diffusion\" if save_outputs_to_google_drive else \"/content/outputs\"\n",
        "      !mkdir -p $model_path\n",
        "      !mkdir -p $outputs_path \n",
        "    except:\n",
        "      save_outputs_to_google_drive = False\n",
        "      save_models_to_google_drive = False\n",
        "\n",
        "\n",
        "\n",
        "#If you want to run it locally change it to true\n",
        "is_local = True\n",
        "skip_installs = False\n",
        "if(is_local):\n",
        "  model_path = \"/home/jon/notebooks/majesty-diffusion/models\"\n",
        "  outputs_path = \"/home/jon/notebooks/majesty-diffusion/outputs\"\n",
        "  skip_installs = False\n",
        "\n",
        "print(f\"Model will be stored at {model_path}\")\n",
        "print(f\"Outputs will be saved to {outputs_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "5Fxt-5TaYBs2"
      },
      "outputs": [],
      "source": [
        "#@title Model settings\n",
        "#@markdown The `original` model is the model trained by CompVis in the LAION-400M dataset\n",
        "#@markdown <br>The `finetuned` model is a finetune of the `original` model by Jack000 that generates less watermarks, but is a bit worse in text synthesis. Colab Free does not have enough run for the finetuned (for now)\n",
        "latent_diffusion_model = 'original' #@param [\"original\", \"finetuned\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEVSOJ4f0B21"
      },
      "source": [
        "# Setup stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "NHgUAp48qwoG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'latent-diffusion'...\n",
            "remote: Enumerating objects: 313, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 313 (delta 8), reused 14 (delta 6), pack-reused 295\u001b[K\n",
            "Receiving objects: 100% (313/313), 28.40 MiB | 35.68 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n",
            "Cloning into 'taming-transformers'...\n",
            "remote: Enumerating objects: 1335, done.\u001b[K\n",
            "remote: Total 1335 (delta 0), reused 0 (delta 0), pack-reused 1335\u001b[K\n",
            "Receiving objects: 100% (1335/1335), 409.77 MiB | 61.46 MiB/s, done.\n",
            "Resolving deltas: 100% (278/278), done.\n",
            "Cloning into 'GFPGAN'...\n",
            "remote: Enumerating objects: 426, done.\u001b[K\n",
            "remote: Total 426 (delta 0), reused 0 (delta 0), pack-reused 426\u001b[K\n",
            "Receiving objects: 100% (426/426), 5.36 MiB | 20.46 MiB/s, done.\n",
            "Resolving deltas: 100% (214/214), done.\n",
            "Cloning into 'majesty-diffusion'...\n",
            "remote: Enumerating objects: 225, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 225 (delta 12), reused 13 (delta 8), pack-reused 196\u001b[K\n",
            "Receiving objects: 100% (225/225), 115.90 KiB | 1.90 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "Cloning into 'aesthetic-predictor'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 67 (delta 21), reused 28 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n",
            "Requirement already satisfied: tensorflow in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (2.9.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (20.9)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (61.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (1.22.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (3.19.4)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.4)\n",
            "Obtaining file:///home/jon/notebooks/majesty-diffusion/taming-transformers\n",
            "Requirement already satisfied: torch in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from taming-transformers==0.0.1) (1.11.0)\n",
            "Requirement already satisfied: numpy in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from taming-transformers==0.0.1) (1.22.3)\n",
            "Requirement already satisfied: tqdm in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from taming-transformers==0.0.1) (4.64.0)\n",
            "Requirement already satisfied: typing_extensions in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torch->taming-transformers==0.0.1) (4.1.1)\n",
            "Installing collected packages: taming-transformers\n",
            "  Attempting uninstall: taming-transformers\n",
            "    Found existing installation: taming-transformers 0.0.1\n",
            "    Uninstalling taming-transformers-0.0.1:\n",
            "      Successfully uninstalled taming-transformers-0.0.1\n",
            "  Running setup.py develop for taming-transformers\n",
            "Successfully installed taming-transformers-0.0.1\n",
            "Requirement already satisfied: transformers in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (4.19.2)\n",
            "Requirement already satisfied: requests in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from transformers) (1.22.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: dotmap in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (1.3.30)\n",
            "Requirement already satisfied: resize-right in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (0.0.2)\n",
            "Requirement already satisfied: piq in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (0.7.0)\n",
            "Requirement already satisfied: torchvision!=0.9.*,>=0.6.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from piq) (0.12.0)\n",
            "Requirement already satisfied: typing_extensions in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torchvision!=0.9.*,>=0.6.1->piq) (4.1.1)\n",
            "Requirement already satisfied: numpy in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torchvision!=0.9.*,>=0.6.1->piq) (1.22.3)\n",
            "Requirement already satisfied: requests in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torchvision!=0.9.*,>=0.6.1->piq) (2.27.1)\n",
            "Requirement already satisfied: torch in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torchvision!=0.9.*,>=0.6.1->piq) (1.11.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torchvision!=0.9.*,>=0.6.1->piq) (9.1.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (3.3)\n",
            "Requirement already satisfied: lpips in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (0.1.4)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from lpips) (0.12.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from lpips) (1.11.0)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from lpips) (4.64.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from lpips) (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from lpips) (1.22.3)\n",
            "Requirement already satisfied: typing_extensions in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torch>=0.4.0->lpips) (4.1.1)\n",
            "Requirement already satisfied: requests in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torchvision>=0.2.1->lpips) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torchvision>=0.2.1->lpips) (9.1.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision>=0.2.1->lpips) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision>=0.2.1->lpips) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision>=0.2.1->lpips) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision>=0.2.1->lpips) (1.26.9)\n",
            "Requirement already satisfied: basicsr in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (1.3.5)\n",
            "Requirement already satisfied: yapf in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (0.32.0)\n",
            "Requirement already satisfied: scikit-image in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (0.19.2)\n",
            "Requirement already satisfied: torch>=1.7 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (1.11.0)\n",
            "Requirement already satisfied: Pillow in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (9.1.1)\n",
            "Requirement already satisfied: scipy in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (1.8.1)\n",
            "Requirement already satisfied: lmdb in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (1.3.0)\n",
            "Requirement already satisfied: requests in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (2.27.1)\n",
            "Requirement already satisfied: torchvision in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (0.12.0)\n",
            "Requirement already satisfied: tb-nightly in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (2.10.0a20220604)\n",
            "Requirement already satisfied: numpy in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (1.22.3)\n",
            "Requirement already satisfied: pyyaml in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (6.0)\n",
            "Requirement already satisfied: opencv-python in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (4.5.5.64)\n",
            "Requirement already satisfied: tqdm in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (4.64.0)\n",
            "Requirement already satisfied: future in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (0.18.2)\n",
            "Requirement already satisfied: addict in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr) (2.4.0)\n",
            "Requirement already satisfied: typing_extensions in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torch>=1.7->basicsr) (4.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->basicsr) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->basicsr) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->basicsr) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->basicsr) (2022.5.18.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from scikit-image->basicsr) (2022.5.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from scikit-image->basicsr) (20.9)\n",
            "Requirement already satisfied: networkx>=2.2 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from scikit-image->basicsr) (2.8.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from scikit-image->basicsr) (2.19.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from scikit-image->basicsr) (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from packaging>=20.0->scikit-image->basicsr) (3.0.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (61.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (2.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (1.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (2.6.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (3.3.7)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (3.19.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from tb-nightly->basicsr) (1.46.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (4.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (1.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->basicsr) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->basicsr) (3.2.0)\n",
            "Requirement already satisfied: facexlib in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (0.2.3)\n",
            "Requirement already satisfied: torchvision in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib) (0.12.0)\n",
            "Requirement already satisfied: scipy in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib) (1.8.1)\n",
            "Requirement already satisfied: numba in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib) (0.55.2)\n",
            "Requirement already satisfied: opencv-python in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib) (4.5.5.64)\n",
            "Requirement already satisfied: tqdm in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib) (4.64.0)\n",
            "Requirement already satisfied: numpy in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib) (1.22.3)\n",
            "Requirement already satisfied: Pillow in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib) (9.1.1)\n",
            "Requirement already satisfied: filterpy in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib) (1.4.5)\n",
            "Requirement already satisfied: torch in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib) (1.11.0)\n",
            "Requirement already satisfied: matplotlib in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from filterpy->facexlib) (3.5.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib) (4.33.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib) (3.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib) (20.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->filterpy->facexlib) (1.16.0)\n",
            "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from numba->facexlib) (0.38.1)\n",
            "Requirement already satisfied: setuptools in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from numba->facexlib) (61.2.0)\n",
            "Requirement already satisfied: typing_extensions in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torch->facexlib) (4.1.1)\n",
            "Requirement already satisfied: requests in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torchvision->facexlib) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision->facexlib) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision->facexlib) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision->facexlib) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from requests->torchvision->facexlib) (2.0.4)\n",
            "Collecting realesrgan\n",
            "  Using cached realesrgan-0.2.5.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from realesrgan) (1.22.3)\n",
            "Requirement already satisfied: Pillow in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from realesrgan) (9.1.1)\n",
            "Requirement already satisfied: torch>=1.7 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from realesrgan) (1.11.0)\n",
            "Requirement already satisfied: tqdm in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from realesrgan) (4.64.0)\n",
            "Requirement already satisfied: basicsr>=1.3.3.11 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from realesrgan) (1.3.5)\n",
            "Requirement already satisfied: torchvision in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from realesrgan) (0.12.0)\n",
            "Collecting gfpgan>=0.2.1\n",
            "  Using cached gfpgan-1.3.2-py3-none-any.whl (47 kB)\n",
            "Requirement already satisfied: facexlib>=0.2.0.3 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from realesrgan) (0.2.3)\n",
            "Requirement already satisfied: opencv-python in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from realesrgan) (4.5.5.64)\n",
            "Requirement already satisfied: requests in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr>=1.3.3.11->realesrgan) (2.27.1)\n",
            "Requirement already satisfied: pyyaml in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr>=1.3.3.11->realesrgan) (6.0)\n",
            "Requirement already satisfied: scikit-image in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr>=1.3.3.11->realesrgan) (0.19.2)\n",
            "Requirement already satisfied: tb-nightly in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr>=1.3.3.11->realesrgan) (2.10.0a20220604)\n",
            "Requirement already satisfied: scipy in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr>=1.3.3.11->realesrgan) (1.8.1)\n",
            "Requirement already satisfied: yapf in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr>=1.3.3.11->realesrgan) (0.32.0)\n",
            "Requirement already satisfied: addict in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr>=1.3.3.11->realesrgan) (2.4.0)\n",
            "Requirement already satisfied: future in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr>=1.3.3.11->realesrgan) (0.18.2)\n",
            "Requirement already satisfied: lmdb in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from basicsr>=1.3.3.11->realesrgan) (1.3.0)\n",
            "Requirement already satisfied: filterpy in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib>=0.2.0.3->realesrgan) (1.4.5)\n",
            "Requirement already satisfied: numba in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from facexlib>=0.2.0.3->realesrgan) (0.55.2)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.20.3.zip (7.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from torch>=1.7->realesrgan) (4.1.1)\n",
            "Requirement already satisfied: matplotlib in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from filterpy->facexlib>=0.2.0.3->realesrgan) (3.5.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->realesrgan) (4.33.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->realesrgan) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->realesrgan) (3.0.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->realesrgan) (1.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->realesrgan) (20.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from matplotlib->filterpy->facexlib>=0.2.0.3->realesrgan) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->filterpy->facexlib>=0.2.0.3->realesrgan) (1.16.0)\n",
            "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from numba->facexlib>=0.2.0.3->realesrgan) (0.38.1)\n",
            "Requirement already satisfied: setuptools in /home/jon/anaconda3/envs/majesty/lib/python3.10/site-packages (from numba->facexlib>=0.2.0.3->realesrgan) (61.2.0)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/opencv-python/\u001b[0m\n",
            "Collecting opencv-python\n",
            "  Using cached opencv_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.4 MB)\n",
            "  Using cached opencv_python-4.5.4.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
            "  Using cached opencv_python-4.5.4.58-cp310-cp310-manylinux2014_x86_64.whl (60.3 MB)\n",
            "  Using cached opencv-python-4.5.3.56.tar.gz (89.2 MB)\n",
            "  Installing build dependencies ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
            "   command: /home/jon/anaconda3/envs/majesty/bin/python /tmp/pip-standalone-pip-eq0ik1yj/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-67roatzr/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools wheel scikit-build cmake pip 'numpy==1.13.3; python_version=='\"'\"'3.6'\"'\"' and platform_machine != '\"'\"'aarch64'\"'\"' and platform_machine != '\"'\"'arm64'\"'\"'' 'numpy==1.19.3; python_version>='\"'\"'3.6'\"'\"' and sys_platform == '\"'\"'linux'\"'\"' and platform_machine == '\"'\"'aarch64'\"'\"'' 'numpy==1.21.0; python_version>='\"'\"'3.6'\"'\"' and sys_platform == '\"'\"'darwin'\"'\"' and platform_machine == '\"'\"'arm64'\"'\"'' 'numpy==1.14.5; python_version=='\"'\"'3.7'\"'\"' and platform_machine != '\"'\"'aarch64'\"'\"' and platform_machine != '\"'\"'arm64'\"'\"'' 'numpy==1.17.3; python_version=='\"'\"'3.8'\"'\"' and platform_machine != '\"'\"'aarch64'\"'\"' and platform_machine != '\"'\"'arm64'\"'\"'' 'numpy==1.19.3; python_version>='\"'\"'3.9'\"'\"' and platform_machine != '\"'\"'aarch64'\"'\"' and platform_machine != '\"'\"'arm64'\"'\"''\n",
            "       cwd: None\n",
            "  Complete output (816 lines):\n",
            "  Ignoring numpy: markers 'python_version == \"3.6\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
            "  Ignoring numpy: markers 'python_version >= \"3.6\" and sys_platform == \"linux\" and platform_machine == \"aarch64\"' don't match your environment\n",
            "  Ignoring numpy: markers 'python_version >= \"3.6\" and sys_platform == \"darwin\" and platform_machine == \"arm64\"' don't match your environment\n",
            "  Ignoring numpy: markers 'python_version == \"3.7\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
            "  Ignoring numpy: markers 'python_version == \"3.8\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
            "  Collecting setuptools\n",
            "    Using cached setuptools-62.3.2-py3-none-any.whl (1.2 MB)\n",
            "  Collecting wheel\n",
            "    Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
            "  Collecting scikit-build\n",
            "    Using cached scikit_build-0.15.0-py2.py3-none-any.whl (77 kB)\n",
            "  Collecting cmake\n",
            "    Using cached cmake-3.22.4-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
            "  Collecting pip\n",
            "    Using cached pip-22.1.2-py3-none-any.whl (2.1 MB)\n",
            "  Collecting numpy==1.19.3\n",
            "    Using cached numpy-1.19.3.zip (7.3 MB)\n",
            "    Installing build dependencies: started\n",
            "    Installing build dependencies: finished with status 'done'\n",
            "    Getting requirements to build wheel: started\n",
            "    Getting requirements to build wheel: finished with status 'done'\n",
            "      Preparing wheel metadata: started\n",
            "      Preparing wheel metadata: finished with status 'done'\n",
            "  Collecting packaging\n",
            "    Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
            "  Collecting distro\n",
            "    Using cached distro-1.7.0-py3-none-any.whl (20 kB)\n",
            "  Collecting pyparsing!=3.0.5,>=2.0.2\n",
            "    Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "  Building wheels for collected packages: numpy\n",
            "    Building wheel for numpy (PEP 517): started\n",
            "    Building wheel for numpy (PEP 517): finished with status 'error'\n",
            "    ERROR: Command errored out with exit status 1:\n",
            "     command: /home/jon/anaconda3/envs/majesty/bin/python /tmp/tmpw82n4r60_in_process.py build_wheel /tmp/tmpjr6fsfnb\n",
            "         cwd: /tmp/pip-install-df_mlqrh/numpy_6f4d1209cd4742ff83295a0cdcc9940c\n",
            "    Complete output (776 lines):\n",
            "    setup.py:67: RuntimeWarning: NumPy 1.19.3 may not yet support Python 3.10.\n",
            "      warnings.warn(\n",
            "    Running from numpy source directory.\n",
            "    Cythonizing sources\n",
            "    numpy/random/_bounded_integers.pxd.in has not changed\n",
            "    numpy/random/_pcg64.pyx has not changed\n",
            "    numpy/random/_philox.pyx has not changed\n",
            "    numpy/random/mtrand.pyx has not changed\n",
            "    numpy/random/_generator.pyx has not changed\n",
            "    numpy/random/_common.pyx has not changed\n",
            "    Processing numpy/random/_bounded_integers.pyx\n",
            "    numpy/random/_mt19937.pyx has not changed\n",
            "    numpy/random/_sfc64.pyx has not changed\n",
            "    numpy/random/_bounded_integers.pyx.in has not changed\n",
            "    numpy/random/bit_generator.pyx has not changed\n",
            "    blas_opt_info:\n",
            "    blas_mkl_info:\n",
            "    customize UnixCCompiler\n",
            "      FOUND:\n",
            "        libraries = ['mkl_rt', 'pthread']\n",
            "        library_dirs = ['/home/jon/anaconda3/envs/majesty/lib']\n",
            "        define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
            "        include_dirs = ['/usr/local/include', '/usr/include', '/home/jon/anaconda3/envs/majesty/include']\n",
            "  \n",
            "      FOUND:\n",
            "        libraries = ['mkl_rt', 'pthread']\n",
            "        library_dirs = ['/home/jon/anaconda3/envs/majesty/lib']\n",
            "        define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
            "        include_dirs = ['/usr/local/include', '/usr/include', '/home/jon/anaconda3/envs/majesty/include']\n",
            "  \n",
            "    non-existing path in 'numpy/distutils': 'site.cfg'\n",
            "    lapack_opt_info:\n",
            "    lapack_mkl_info:\n",
            "      FOUND:\n",
            "        libraries = ['mkl_rt', 'pthread']\n",
            "        library_dirs = ['/home/jon/anaconda3/envs/majesty/lib']\n",
            "        define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
            "        include_dirs = ['/usr/local/include', '/usr/include', '/home/jon/anaconda3/envs/majesty/include']\n",
            "  \n",
            "      FOUND:\n",
            "        libraries = ['mkl_rt', 'pthread']\n",
            "        library_dirs = ['/home/jon/anaconda3/envs/majesty/lib']\n",
            "        define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
            "        include_dirs = ['/usr/local/include', '/usr/include', '/home/jon/anaconda3/envs/majesty/include']\n",
            "  \n",
            "    /tmp/pip-build-env-czqghj_p/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\n",
            "      warnings.warn(msg)\n",
            "    running bdist_wheel\n",
            "    running build\n",
            "    running config_cc\n",
            "    unifing config_cc, config, build_clib, build_ext, build commands --compiler options\n",
            "    running config_fc\n",
            "    unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\n",
            "    running build_src\n",
            "    build_src\n",
            "    building py_modules sources\n",
            "    building library \"npymath\" sources\n",
            "    Could not locate executable gfortran\n",
            "    Could not locate executable f95\n",
            "    Could not locate executable ifort\n",
            "    Could not locate executable ifc\n",
            "    Could not locate executable lf95\n",
            "    Could not locate executable pgfortran\n",
            "    Could not locate executable nvfortran\n",
            "    Could not locate executable f90\n",
            "    Could not locate executable f77\n",
            "    Could not locate executable fort\n",
            "    Could not locate executable efort\n",
            "    Could not locate executable efc\n",
            "    Could not locate executable g77\n",
            "    Could not locate executable g95\n",
            "    Could not locate executable pathf95\n",
            "    Could not locate executable nagfor\n",
            "    don't know how to compile Fortran code on platform 'posix'\n",
            "      adding 'build/src.linux-x86_64-3.10/numpy/core/src/npymath' to include_dirs.\n",
            "    None - nothing done with h_files = ['build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_internal.h']\n",
            "    building library \"npysort\" sources\n",
            "      adding 'build/src.linux-x86_64-3.10/numpy/core/src/common' to include_dirs.\n",
            "    None - nothing done with h_files = ['build/src.linux-x86_64-3.10/numpy/core/src/common/npy_sort.h', 'build/src.linux-x86_64-3.10/numpy/core/src/common/npy_partition.h', 'build/src.linux-x86_64-3.10/numpy/core/src/common/npy_binsearch.h']\n",
            "    building library \"npyrandom\" sources\n",
            "    building extension \"numpy.core._multiarray_tests\" sources\n",
            "    building extension \"numpy.core._multiarray_umath\" sources\n",
            "      adding 'build/src.linux-x86_64-3.10/numpy/core/src/umath' to include_dirs.\n",
            "      adding 'build/src.linux-x86_64-3.10/numpy/core/src/npymath' to include_dirs.\n",
            "      adding 'build/src.linux-x86_64-3.10/numpy/core/src/common' to include_dirs.\n",
            "    numpy.core - nothing done with h_files = ['build/src.linux-x86_64-3.10/numpy/core/src/umath/funcs.inc', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/simd.inc', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.h', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/matmul.h', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/clip.h', 'build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_internal.h', 'build/src.linux-x86_64-3.10/numpy/core/src/common/templ_common.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/config.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/_numpyconfig.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/__multiarray_api.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/__ufunc_api.h']\n",
            "    building extension \"numpy.core._umath_tests\" sources\n",
            "    building extension \"numpy.core._rational_tests\" sources\n",
            "    building extension \"numpy.core._struct_ufunc_tests\" sources\n",
            "    building extension \"numpy.core._operand_flag_tests\" sources\n",
            "    building extension \"numpy.fft._pocketfft_internal\" sources\n",
            "    building extension \"numpy.linalg.lapack_lite\" sources\n",
            "    building extension \"numpy.linalg._umath_linalg\" sources\n",
            "    building extension \"numpy.random._mt19937\" sources\n",
            "    building extension \"numpy.random._philox\" sources\n",
            "    building extension \"numpy.random._pcg64\" sources\n",
            "    building extension \"numpy.random._sfc64\" sources\n",
            "    building extension \"numpy.random._common\" sources\n",
            "    building extension \"numpy.random.bit_generator\" sources\n",
            "    building extension \"numpy.random._generator\" sources\n",
            "    building extension \"numpy.random._bounded_integers\" sources\n",
            "    building extension \"numpy.random.mtrand\" sources\n",
            "    building data_files sources\n",
            "    build_src: building npy-pkg config files\n",
            "    running build_py\n",
            "    creating build/lib.linux-x86_64-3.10\n",
            "    creating build/lib.linux-x86_64-3.10/numpy\n",
            "    copying numpy/_distributor_init.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    copying numpy/matlib.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    copying numpy/version.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    copying numpy/_pytesttester.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    copying numpy/ctypeslib.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    copying numpy/conftest.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    copying numpy/dual.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    copying numpy/_globals.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    copying numpy/setup.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    copying numpy/__init__.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    copying build/src.linux-x86_64-3.10/numpy/__config__.py -> build/lib.linux-x86_64-3.10/numpy\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/compat\n",
            "    copying numpy/compat/py3k.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
            "    copying numpy/compat/_inspect.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
            "    copying numpy/compat/setup.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
            "    copying numpy/compat/__init__.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/compat/tests\n",
            "    copying numpy/compat/tests/test_compat.py -> build/lib.linux-x86_64-3.10/numpy/compat/tests\n",
            "    copying numpy/compat/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/compat/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/_add_newdocs.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/defchararray.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/arrayprint.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/_string_helpers.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/fromnumeric.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/records.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/machar.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/_type_aliases.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/einsumfunc.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/shape_base.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/_internal.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/getlimits.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/setup_common.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/numeric.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/cversions.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/numerictypes.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/multiarray.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/umath_tests.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/_asarray.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/_methods.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/function_base.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/_dtype_ctypes.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/_exceptions.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/setup.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/overrides.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/umath.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/__init__.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/_ufunc_config.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/memmap.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/_dtype.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    copying numpy/core/code_generators/generate_numpy_api.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_einsum.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_scalar_methods.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_indexerrors.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_scalarmath.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_getlimits.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_machar.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test__exceptions.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_ufunc.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_abc.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_defchararray.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_scalarinherit.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_shape_base.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_errstate.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_multiarray.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_scalar_ctors.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_mem_overlap.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_memmap.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_umath_accuracy.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_cpu_features.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_indexing.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_umath.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_dtype.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_api.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_numerictypes.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_deprecations.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_overrides.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_longdouble.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_scalarbuffer.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_function_base.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_unicode.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_umath_complex.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_protocols.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_half.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_nditer.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_numeric.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_records.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/_locales.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_print.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_item_selection.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_arrayprint.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_datetime.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_scalarprint.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_extint128.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    copying numpy/core/tests/test_conversion_utils.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/system_info.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/lib2def.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/exec_command.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/numpy_distribution.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/cpuinfo.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/_shell_utils.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/core.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/log.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/npy_pkg_config.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/pathccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/msvc9compiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/misc_util.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/conv_template.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/setup.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/line_endings.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/from_template.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/intelccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/ccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/msvccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/extension.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/unixccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying numpy/distutils/mingw32ccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    copying build/src.linux-x86_64-3.10/numpy/distutils/__config__.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/install.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/build.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/install_clib.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/install_headers.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/sdist.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/autodist.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/bdist_rpm.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/build_ext.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/egg_info.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/config.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/develop.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/install_data.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/build_clib.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/build_scripts.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/build_py.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/config_compiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/build_src.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    copying numpy/distutils/command/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/lahey.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/nag.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/environment.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/compaq.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/g95.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/pg.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/hpux.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/pathf95.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/vast.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/intel.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/absoft.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/sun.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/none.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/ibm.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/nv.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/gnu.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    copying numpy/distutils/fcompiler/mips.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_from_template.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_npy_pkg_config.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_system_info.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_fcompiler_gnu.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_fcompiler_intel.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_fcompiler_nagfor.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_fcompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_exec_command.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_mingw32ccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_misc_util.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/test_shell_utils.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    copying numpy/distutils/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/creation.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/indexing.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/structured_arrays.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/byteswapping.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/internals.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/dispatch.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/misc.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/ufuncs.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/broadcasting.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/constants.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/basics.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/subclassing.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/__init__.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    copying numpy/doc/glossary.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/__main__.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/diagnose.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/f90mod_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/f2py_testing.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/func2subr.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/cb_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/use_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/__version__.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/auxfuncs.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/capi_maps.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/cfuncs.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/setup.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/common_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/__init__.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/f2py2e.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    copying numpy/f2py/crackfortran.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_callback.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_return_logical.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_return_integer.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_quoted_character.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_semicolon_split.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_return_complex.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_size.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_compile_function.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_string.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_common.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_array_from_pyobj.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_block_docstring.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/util.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_return_real.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_parameter.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_mixed.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_assumed_shape.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_kind.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_crackfortran.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    copying numpy/f2py/tests/test_return_character.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/fft\n",
            "    copying numpy/fft/_pocketfft.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
            "    copying numpy/fft/setup.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
            "    copying numpy/fft/helper.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
            "    copying numpy/fft/__init__.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
            "    copying numpy/fft/tests/test_helper.py -> build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
            "    copying numpy/fft/tests/test_pocketfft.py -> build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
            "    copying numpy/fft/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/financial.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/histograms.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/arraypad.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/utils.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/recfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/shape_base.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/index_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/user_array.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/ufunclike.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/polynomial.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/npyio.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/scimath.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/arrayterator.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/arraysetops.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/type_check.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/function_base.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/_datasource.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/_version.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/stride_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/setup.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/twodim_base.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/mixins.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/nanfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/__init__.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/format.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    copying numpy/lib/_iotools.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_ufunclike.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_arraypad.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_shape_base.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_recfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test__datasource.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test__iotools.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_format.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_io.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_arraysetops.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_stride_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_mixins.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_utils.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_financial.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_index_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_polynomial.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_function_base.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_type_check.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_histograms.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_arrayterator.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_nanfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test__version.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_twodim_base.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    copying numpy/lib/tests/test_packbits.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/linalg\n",
            "    copying numpy/linalg/setup.py -> build/lib.linux-x86_64-3.10/numpy/linalg\n",
            "    copying numpy/linalg/linalg.py -> build/lib.linux-x86_64-3.10/numpy/linalg\n",
            "    copying numpy/linalg/__init__.py -> build/lib.linux-x86_64-3.10/numpy/linalg\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
            "    copying numpy/linalg/tests/test_linalg.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
            "    copying numpy/linalg/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
            "    copying numpy/linalg/tests/test_build.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
            "    copying numpy/linalg/tests/test_deprecations.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
            "    copying numpy/linalg/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/ma\n",
            "    copying numpy/ma/mrecords.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
            "    copying numpy/ma/core.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
            "    copying numpy/ma/setup.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
            "    copying numpy/ma/testutils.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
            "    copying numpy/ma/bench.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
            "    copying numpy/ma/timer_comparison.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
            "    copying numpy/ma/__init__.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
            "    copying numpy/ma/extras.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
            "    copying numpy/ma/tests/test_extras.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
            "    copying numpy/ma/tests/test_old_ma.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
            "    copying numpy/ma/tests/test_core.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
            "    copying numpy/ma/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
            "    copying numpy/ma/tests/test_deprecations.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
            "    copying numpy/ma/tests/test_mrecords.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
            "    copying numpy/ma/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
            "    copying numpy/ma/tests/test_subclassing.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
            "    copying numpy/matrixlib/setup.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
            "    copying numpy/matrixlib/defmatrix.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
            "    copying numpy/matrixlib/__init__.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
            "    copying numpy/matrixlib/tests/test_defmatrix.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
            "    copying numpy/matrixlib/tests/test_multiarray.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
            "    copying numpy/matrixlib/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
            "    copying numpy/matrixlib/tests/test_masked_matrix.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
            "    copying numpy/matrixlib/tests/test_interaction.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
            "    copying numpy/matrixlib/tests/test_numeric.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
            "    copying numpy/matrixlib/tests/test_matrix_linalg.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
            "    copying numpy/matrixlib/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    copying numpy/polynomial/legendre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    copying numpy/polynomial/chebyshev.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    copying numpy/polynomial/_polybase.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    copying numpy/polynomial/polynomial.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    copying numpy/polynomial/laguerre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    copying numpy/polynomial/hermite_e.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    copying numpy/polynomial/polyutils.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    copying numpy/polynomial/hermite.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    copying numpy/polynomial/setup.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    copying numpy/polynomial/__init__.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    copying numpy/polynomial/tests/test_polyutils.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    copying numpy/polynomial/tests/test_hermite_e.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    copying numpy/polynomial/tests/test_chebyshev.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    copying numpy/polynomial/tests/test_polynomial.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    copying numpy/polynomial/tests/test_classes.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    copying numpy/polynomial/tests/test_laguerre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    copying numpy/polynomial/tests/test_legendre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    copying numpy/polynomial/tests/test_hermite.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    copying numpy/polynomial/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    copying numpy/polynomial/tests/test_printing.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/random\n",
            "    copying numpy/random/_pickle.py -> build/lib.linux-x86_64-3.10/numpy/random\n",
            "    copying numpy/random/setup.py -> build/lib.linux-x86_64-3.10/numpy/random\n",
            "    copying numpy/random/__init__.py -> build/lib.linux-x86_64-3.10/numpy/random\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/test_direct.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/test_smoke.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/test_randomstate.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/test_generator_mt19937_regressions.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/test_generator_mt19937.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/test_randomstate_regression.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/test_seed_sequence.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/test_random.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    copying numpy/random/tests/test_extending.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/testing\n",
            "    copying numpy/testing/utils.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
            "    copying numpy/testing/setup.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
            "    copying numpy/testing/print_coercion_tables.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
            "    copying numpy/testing/__init__.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
            "    copying numpy/testing/_private/nosetester.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
            "    copying numpy/testing/_private/utils.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
            "    copying numpy/testing/_private/parameterized.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
            "    copying numpy/testing/_private/decorators.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
            "    copying numpy/testing/_private/noseclasses.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
            "    copying numpy/testing/_private/__init__.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
            "    copying numpy/testing/tests/test_utils.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
            "    copying numpy/testing/tests/test_doctesting.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
            "    copying numpy/testing/tests/test_decorators.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
            "    copying numpy/testing/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
            "    creating build/lib.linux-x86_64-3.10/numpy/tests\n",
            "    copying numpy/tests/test_ctypeslib.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
            "    copying numpy/tests/test_public_api.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
            "    copying numpy/tests/test_numpy_version.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
            "    copying numpy/tests/test_scripts.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
            "    copying numpy/tests/test_reloading.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
            "    copying numpy/tests/test_matlib.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
            "    copying numpy/tests/test_warnings.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
            "    copying numpy/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
            "    running build_clib\n",
            "    customize UnixCCompiler\n",
            "    customize UnixCCompiler using new_build_clib\n",
            "    building 'npymath' library\n",
            "    compiling C sources\n",
            "    C compiler: gcc -pthread -B /home/jon/anaconda3/envs/majesty/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC\n",
            "  \n",
            "    creating build/temp.linux-x86_64-3.10\n",
            "    creating build/temp.linux-x86_64-3.10/numpy\n",
            "    creating build/temp.linux-x86_64-3.10/numpy/core\n",
            "    creating build/temp.linux-x86_64-3.10/numpy/core/src\n",
            "    creating build/temp.linux-x86_64-3.10/numpy/core/src/npymath\n",
            "    creating build/temp.linux-x86_64-3.10/build\n",
            "    creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10\n",
            "    creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy\n",
            "    creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core\n",
            "    creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src\n",
            "    creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/npymath\n",
            "    compile options: '-Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/jon/anaconda3/envs/majesty/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
            "    gcc: numpy/core/src/npymath/npy_math.cgcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/ieee754.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_complex.cgcc: numpy/core/src/npymath/halffloat.c\n",
            "  \n",
            "  \n",
            "    ar: adding 4 object files to build/temp.linux-x86_64-3.10/libnpymath.a\n",
            "    building 'npysort' library\n",
            "    compiling C sources\n",
            "    C compiler: gcc -pthread -B /home/jon/anaconda3/envs/majesty/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC\n",
            "  \n",
            "    creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/npysort\n",
            "    compile options: '-Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/jon/anaconda3/envs/majesty/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/quicksort.cgcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/mergesort.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/timsort.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/heapsort.cgcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/radixsort.c\n",
            "  \n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/selection.c\n",
            "  \n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/binsearch.c\n",
            "    ar: adding 7 object files to build/temp.linux-x86_64-3.10/libnpysort.a\n",
            "    building 'npyrandom' library\n",
            "    compiling C sources\n",
            "    C compiler: gcc -pthread -B /home/jon/anaconda3/envs/majesty/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC\n",
            "  \n",
            "    creating build/temp.linux-x86_64-3.10/numpy/random\n",
            "    creating build/temp.linux-x86_64-3.10/numpy/random/src\n",
            "    creating build/temp.linux-x86_64-3.10/numpy/random/src/distributions\n",
            "    compile options: '-Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/jon/anaconda3/envs/majesty/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
            "    gcc: numpy/random/src/distributions/logfactorial.cgcc: numpy/random/src/distributions/distributions.c\n",
            "  \n",
            "    gcc: numpy/random/src/distributions/random_mvhg_count.cgcc: numpy/random/src/distributions/random_mvhg_marginals.c\n",
            "  \n",
            "    gcc: numpy/random/src/distributions/random_hypergeometric.c\n",
            "    ar: adding 5 object files to build/temp.linux-x86_64-3.10/libnpyrandom.a\n",
            "    running build_ext\n",
            "    customize UnixCCompiler\n",
            "    customize UnixCCompiler using new_build_ext\n",
            "    building 'numpy.core._multiarray_tests' extension\n",
            "    compiling C sources\n",
            "    C compiler: gcc -pthread -B /home/jon/anaconda3/envs/majesty/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC\n",
            "  \n",
            "    creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray\n",
            "    creating build/temp.linux-x86_64-3.10/numpy/core/src/common\n",
            "    compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/jon/anaconda3/envs/majesty/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/_multiarray_tests.cgcc: numpy/core/src/common/mem_overlap.c\n",
            "  \n",
            "    gcc -pthread -B /home/jon/anaconda3/envs/majesty/compiler_compat -shared -Wl,-rpath,/home/jon/anaconda3/envs/majesty/lib -Wl,-rpath-link,/home/jon/anaconda3/envs/majesty/lib -L/home/jon/anaconda3/envs/majesty/lib -Wl,-rpath,/home/jon/anaconda3/envs/majesty/lib -Wl,-rpath-link,/home/jon/anaconda3/envs/majesty/lib -L/home/jon/anaconda3/envs/majesty/lib build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/_multiarray_tests.o build/temp.linux-x86_64-3.10/numpy/core/src/common/mem_overlap.o -Lbuild/temp.linux-x86_64-3.10 -lnpymath -o build/lib.linux-x86_64-3.10/numpy/core/_multiarray_tests.cpython-310-x86_64-linux-gnu.so\n",
            "    building 'numpy.core._multiarray_umath' extension\n",
            "    compiling C sources\n",
            "    C compiler: gcc -pthread -B /home/jon/anaconda3/envs/majesty/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC\n",
            "  \n",
            "    creating build/temp.linux-x86_64-3.10/numpy/core/src/multiarray\n",
            "    creating build/temp.linux-x86_64-3.10/numpy/core/src/umath\n",
            "    creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/umath\n",
            "    creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/common\n",
            "    compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DSCIPY_MKL_H -DHAVE_CBLAS -I/usr/local/include -I/usr/include -I/home/jon/anaconda3/envs/majesty/include -Ibuild/src.linux-x86_64-3.10/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/jon/anaconda3/envs/majesty/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
            "    gcc: numpy/core/src/multiarray/alloc.cgcc: numpy/core/src/multiarray/array_assign_scalar.c\n",
            "    gcc: numpy/core/src/multiarray/buffer.c\n",
            "    gcc: numpy/core/src/multiarray/common.cgcc: numpy/core/src/multiarray/conversion_utils.c\n",
            "    gcc: numpy/core/src/multiarray/datetime_strings.cgcc: numpy/core/src/multiarray/descriptor.c\n",
            "  \n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/einsum.c\n",
            "  \n",
            "  \n",
            "    gcc: numpy/core/src/multiarray/arrayobject.c\n",
            "    gcc: numpy/core/src/multiarray/array_assign_array.c\n",
            "    gcc: numpy/core/src/multiarray/ctors.c\n",
            "    gcc: numpy/core/src/multiarray/calculation.c\n",
            "    gcc: numpy/core/src/multiarray/datetime_busday.c\n",
            "    gcc: numpy/core/src/multiarray/convert.c\n",
            "    gcc: numpy/core/src/multiarray/arrayfunction_override.c\n",
            "    gcc: numpy/core/src/multiarray/convert_datatype.c\n",
            "    gcc: numpy/core/src/multiarray/hashdescr.c\n",
            "    gcc: numpy/core/src/multiarray/compiled_base.c\n",
            "    gcc: numpy/core/src/multiarray/datetime_busdaycal.c\n",
            "    gcc: numpy/core/src/multiarray/dragon4.c\n",
            "    gcc: numpy/core/src/multiarray/item_selection.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/lowlevel_strided_loops.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/arraytypes.c\n",
            "    gcc: numpy/core/src/multiarray/multiarraymodule.c\n",
            "    gcc: numpy/core/src/multiarray/datetime.c\n",
            "    gcc: numpy/core/src/multiarray/dtype_transfer.c\n",
            "    gcc: numpy/core/src/multiarray/nditer_constr.c\n",
            "    gcc: numpy/core/src/multiarray/refcount.c\n",
            "    gcc: numpy/core/src/multiarray/sequence.c\n",
            "    gcc: numpy/core/src/multiarray/scalarapi.c\n",
            "    gcc: numpy/core/src/multiarray/shape.c\n",
            "    gcc: numpy/core/src/multiarray/iterators.c\n",
            "    gcc: numpy/core/src/multiarray/nditer_pywrap.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.c\n",
            "    numpy/core/src/multiarray/scalartypes.c.src: In function ‘float_arrtype_hash’:\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2967:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
            "         return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
            "                               ^\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: expected ‘PyObject * {aka struct _object *}’ but argument is of type ‘double’\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2967:12: error: too few arguments to function ‘_Py_HashDouble’\n",
            "         return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
            "                ^~~~~~~~~~~~~~\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: declared here\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src: In function ‘cfloat_arrtype_hash’:\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2975:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
            "         hashreal = _Py_HashDouble((double)\n",
            "                                   ^\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: expected ‘PyObject * {aka struct _object *}’ but argument is of type ‘double’\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2975:16: error: too few arguments to function ‘_Py_HashDouble’\n",
            "         hashreal = _Py_HashDouble((double)\n",
            "                    ^~~~~~~~~~~~~~\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: declared here\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2981:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
            "         hashimag = _Py_HashDouble((double)\n",
            "                                   ^\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: expected ‘PyObject * {aka struct _object *}’ but argument is of type ‘double’\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2981:16: error: too few arguments to function ‘_Py_HashDouble’\n",
            "         hashimag = _Py_HashDouble((double)\n",
            "                    ^~~~~~~~~~~~~~\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: declared here\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src: In function ‘longdouble_arrtype_hash’:\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2967:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
            "         return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
            "                               ^\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: expected ‘PyObject * {aka struct _object *}’ but argument is of type ‘double’\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2967:12: error: too few arguments to function ‘_Py_HashDouble’\n",
            "         return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
            "                ^~~~~~~~~~~~~~\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: declared here\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src: In function ‘clongdouble_arrtype_hash’:\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2975:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
            "         hashreal = _Py_HashDouble((double)\n",
            "                                   ^\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: expected ‘PyObject * {aka struct _object *}’ but argument is of type ‘double’\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2975:16: error: too few arguments to function ‘_Py_HashDouble’\n",
            "         hashreal = _Py_HashDouble((double)\n",
            "                    ^~~~~~~~~~~~~~\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: declared here\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2981:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
            "         hashimag = _Py_HashDouble((double)\n",
            "                                   ^\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: expected ‘PyObject * {aka struct _object *}’ but argument is of type ‘double’\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2981:16: error: too few arguments to function ‘_Py_HashDouble’\n",
            "         hashimag = _Py_HashDouble((double)\n",
            "                    ^~~~~~~~~~~~~~\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: declared here\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src: In function ‘half_arrtype_hash’:\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2997:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
            "         return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));\n",
            "                               ^~~~~~~~~~~~~~~~~~\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: expected ‘PyObject * {aka struct _object *}’ but argument is of type ‘double’\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2997:12: error: too few arguments to function ‘_Py_HashDouble’\n",
            "         return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));\n",
            "                ^~~~~~~~~~~~~~\n",
            "    In file included from /home/jon/anaconda3/envs/majesty/include/python3.10/Python.h:77:0,\n",
            "                     from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
            "    /home/jon/anaconda3/envs/majesty/include/python3.10/pyhash.h:10:23: note: declared here\n",
            "     PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
            "                           ^~~~~~~~~~~~~~\n",
            "    numpy/core/src/multiarray/scalartypes.c.src: In function ‘longdouble_arrtype_hash’:\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2968:1: warning: control reaches end of non-void function [-Wreturn-type]\n",
            "     }\n",
            "     ^\n",
            "    numpy/core/src/multiarray/scalartypes.c.src: In function ‘float_arrtype_hash’:\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2968:1: warning: control reaches end of non-void function [-Wreturn-type]\n",
            "     }\n",
            "     ^\n",
            "    numpy/core/src/multiarray/scalartypes.c.src: In function ‘half_arrtype_hash’:\n",
            "    numpy/core/src/multiarray/scalartypes.c.src:2998:1: warning: control reaches end of non-void function [-Wreturn-type]\n",
            "     }\n",
            "     ^\n",
            "    gcc: numpy/core/src/multiarray/temp_elide.c\n",
            "    gcc: numpy/core/src/multiarray/vdot.c\n",
            "    gcc: numpy/core/src/umath/umathmodule.c\n",
            "    gcc: numpy/core/src/multiarray/typeinfo.c\n",
            "    gcc: numpy/core/src/multiarray/usertypes.c\n",
            "    gcc: numpy/core/src/umath/reduction.c\n",
            "    gcc: numpy/core/src/multiarray/number.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.c\n",
            "    gcc: numpy/core/src/umath/ufunc_object.c\n",
            "    gcc: numpy/core/src/umath/ufunc_type_resolution.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/nditer_templ.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/ieee754.c\n",
            "    gcc: numpy/core/src/umath/override.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_complex.c\n",
            "    gcc: numpy/core/src/npymath/npy_math.c\n",
            "    gcc: numpy/core/src/npymath/halffloat.c\n",
            "    gcc: numpy/core/src/common/array_assign.c\n",
            "    gcc: numpy/core/src/common/ucsnarrow.c\n",
            "    gcc: numpy/core/src/multiarray/nditer_api.c\n",
            "    gcc: numpy/core/src/multiarray/flagsobject.c\n",
            "    gcc: numpy/core/src/common/ufunc_override.c\n",
            "    gcc: numpy/core/src/common/mem_overlap.c\n",
            "    gcc: numpy/core/src/common/numpyos.c\n",
            "    gcc: numpy/core/src/umath/extobj.c\n",
            "    gcc: numpy/core/src/multiarray/getset.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/scalarmath.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/common/npy_cpu_features.c\n",
            "    gcc: numpy/core/src/common/npy_longdouble.c\n",
            "    gcc: numpy/core/src/common/cblasfuncs.c\n",
            "    gcc: numpy/core/src/common/python_xerbla.c\n",
            "    gcc: numpy/core/src/multiarray/mapping.c\n",
            "    gcc: numpy/core/src/multiarray/methods.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/matmul.c\n",
            "    gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/clip.c\n",
            "    error: Command \"gcc -pthread -B /home/jon/anaconda3/envs/majesty/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC -O2 -isystem /home/jon/anaconda3/envs/majesty/include -fPIC -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DSCIPY_MKL_H -DHAVE_CBLAS -I/usr/local/include -I/usr/include -I/home/jon/anaconda3/envs/majesty/include -Ibuild/src.linux-x86_64-3.10/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/home/jon/anaconda3/envs/majesty/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.c -o build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.o -MMD -MF build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.o.d\" failed with exit status 1\n",
            "    ----------------------------------------\n",
            "    ERROR: Failed building wheel for numpy\n",
            "  Failed to build numpy\n",
            "  ERROR: Could not build wheels for numpy which use PEP 517 and cannot be installed directly\n",
            "  ----------------------------------------\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/01/9b/be08992293fb21faf35ab98e06924d7407fcfca89d89c5de65442631556a/opencv-python-4.5.3.56.tar.gz#sha256=3c001d3feec7f3140f1fb78dfc52ca28122db8240826882d175a208a89d2731b (from https://pypi.org/simple/opencv-python/) (requires-python:>=3.6). Command errored out with exit status 1: /home/jon/anaconda3/envs/majesty/bin/python /tmp/pip-standalone-pip-eq0ik1yj/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-67roatzr/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools wheel scikit-build cmake pip 'numpy==1.13.3; python_version=='\"'\"'3.6'\"'\"' and platform_machine != '\"'\"'aarch64'\"'\"' and platform_machine != '\"'\"'arm64'\"'\"'' 'numpy==1.19.3; python_version>='\"'\"'3.6'\"'\"' and sys_platform == '\"'\"'linux'\"'\"' and platform_machine == '\"'\"'aarch64'\"'\"'' 'numpy==1.21.0; python_version>='\"'\"'3.6'\"'\"' and sys_platform == '\"'\"'darwin'\"'\"' and platform_machine == '\"'\"'arm64'\"'\"'' 'numpy==1.14.5; python_version=='\"'\"'3.7'\"'\"' and platform_machine != '\"'\"'aarch64'\"'\"' and platform_machine != '\"'\"'arm64'\"'\"'' 'numpy==1.17.3; python_version=='\"'\"'3.8'\"'\"' and platform_machine != '\"'\"'aarch64'\"'\"' and platform_machine != '\"'\"'arm64'\"'\"'' 'numpy==1.19.3; python_version>='\"'\"'3.9'\"'\"' and platform_machine != '\"'\"'aarch64'\"'\"' and platform_machine != '\"'\"'arm64'\"'\"'' Check the logs for full command output.\u001b[0m\n",
            "  Using cached opencv-python-4.5.1.48.tar.gz (88.3 MB)\n",
            "  Installing build dependencies ... \u001b[?25l"
          ]
        }
      ],
      "source": [
        "#@title Installation\n",
        "if(not skip_installs):\n",
        "    import subprocess\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    cards_requiring_downgrade = [\"Tesla T4\", \"V100\"]\n",
        "    if any(cardstr in nvidiasmi_output for cardstr in cards_requiring_downgrade):\n",
        "        downgrade_pytorch_result = subprocess.run(['pip', 'install', 'torch==1.10.2', 'torchvision==0.11.3', '-q'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    import sys\n",
        "    sys.path.append(\".\")\n",
        "    !git clone https://github.com/multimodalart/latent-diffusion\n",
        "    !git clone https://github.com/CompVis/taming-transformers\n",
        "    !git clone https://github.com/TencentARC/GFPGAN\n",
        "    !git clone https://github.com/multimodalart/majesty-diffusion\n",
        "    !git clone https://github.com/LAION-AI/aesthetic-predictor\n",
        "    !pip install tensorflow\n",
        "    !pip install -e ./taming-transformers\n",
        "    !pip install omegaconf>=2.0.0 pytorch-lightning>=1.0.8 torch-fidelity einops\n",
        "    !pip install transformers\n",
        "    !pip install dotmap\n",
        "    !pip install resize-right\n",
        "    !pip install piq\n",
        "    !pip install lpips\n",
        "    !pip install basicsr\n",
        "    !pip install facexlib\n",
        "    !pip install realesrgan\n",
        "\n",
        "    sys.path.append('./taming-transformers')\n",
        "    from taming.models import vqgan\n",
        "    from subprocess import Popen, PIPE\n",
        "    try:\n",
        "        import mmc\n",
        "    except:\n",
        "        # install mmc\n",
        "        !git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing\n",
        "        !pip install poetry\n",
        "        !cd Multi-Modal-Comparators; poetry build\n",
        "        !cd Multi-Modal-Comparators; pip install dist/mmc*.whl\n",
        "        \n",
        "        # optional final step:\n",
        "        #poe napm_installs\n",
        "        !python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\n",
        "    # suppress mmc warmup outputs\n",
        "    import mmc.loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNqCqQDoyZmq"
      },
      "source": [
        "Now, download the checkpoint (~5.7 GB). This will usually take 3-6 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cNHvQBhzyXCI"
      },
      "outputs": [],
      "source": [
        "#@title Download models\n",
        "import os\n",
        "if os.path.isfile(f\"{model_path}/latent_diffusion_txt2img_f8_large.ckpt\"):\n",
        "    print(\"Using Latent Diffusion model saved from Google Drive\")\n",
        "else:    \n",
        "    !wget -O $model_path/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate\n",
        "\n",
        "if os.path.isfile(f\"{model_path}/finetuned_state_dict.pt\"):\n",
        "    print(\"Using Latent Diffusion model saved from Google Drive\")\n",
        "else:    \n",
        "    !wget -O $model_path/finetuned_state_dict.pt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/finetuned_state_dict.pt --no-check-certificate\n",
        "\n",
        "if os.path.isfile(f\"{model_path}/ava_vit_l_14_336_linear.pth\"):\n",
        "  print(\"Using ViT-L/14@336px aesthetic model from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/ava_vit_l_14_336_linear.pth https://multimodal.art/models/ava_vit_l_14_336_linear.pth\n",
        "\n",
        "if os.path.isfile(f\"{model_path}/sa_0_4_vit_l_14_linear.pth\"):\n",
        "  print(\"Using ViT-L/14 aesthetic model from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/sa_0_4_vit_l_14_linear.pth https://multimodal.art/models/sa_0_4_vit_l_14_linear.pth\n",
        "\n",
        "if os.path.isfile(f\"{model_path}/ava_vit_l_14_linear.pth\"):\n",
        "  print(\"Using ViT-L/14 aesthetic model from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/ava_vit_l_14_linear.pth https://multimodal.art/models/ava_vit_l_14_linear.pth\n",
        "\n",
        "if os.path.isfile(f\"{model_path}/ava_vit_b_16_linear.pth\"):\n",
        "  print(\"Using ViT-B/16 aesthetic model from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/ava_vit_b_16_linear.pth http://batbot.tv/ai/models/v-diffusion/ava_vit_b_16_linear.pth\n",
        "if os.path.isfile(f\"{model_path}/sa_0_4_vit_b_16_linear.pth\"):\n",
        "  print(\"Using ViT-B/16 sa aesthetic model already saved\")\n",
        "else:\n",
        "  !wget -O $model_path/sa_0_4_vit_b_32_linear.pth https://multimodal.art/models/sa_0_4_vit_b_16_linear.pth\n",
        "if os.path.isfile(f\"{model_path}/sa_0_4_vit_b_32_linear.pth\"):\n",
        "  print(\"Using ViT-B/32 aesthetic model from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/sa_0_4_vit_b_32_linear.pth https://multimodal.art/models/sa_0_4_vit_b_32_linear.pth\n",
        "if os.path.isfile(f\"{model_path}/openimages_512x_png_embed224.npz\"):\n",
        "  print(\"Using openimages png from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz\n",
        "if os.path.isfile(f\"{model_path}/imagenet_512x_jpg_embed224.npz\"):\n",
        "  print(\"Using imagenet antijpeg from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz\n",
        "if os.path.isfile(f\"{model_path}/GFPGANv1.3.pth\"):\n",
        "  print(\"Using GFPGAN v1.3 from Google Drive\")\n",
        "else:\n",
        "  !wget -O $model_path/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\n",
        "!cp $model_path/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThxmCePqt1mt"
      },
      "source": [
        "Let's also check what type of GPU we've got."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbL2zJ7Pt7Jl"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BPnyd-XUKbfE"
      },
      "outputs": [],
      "source": [
        "#@title Import stuff\n",
        "import argparse, os, sys, glob\n",
        "import torch\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm, trange\n",
        "tqdm_auto_model = __import__(\"tqdm.auto\", fromlist=[None]) \n",
        "sys.modules['tqdm'] = tqdm_auto_model\n",
        "from einops import rearrange\n",
        "from torchvision.utils import make_grid\n",
        "import transformers\n",
        "import gc\n",
        "sys.path.append('./latent-diffusion')\n",
        "from ldm.util import instantiate_from_config\n",
        "from ldm.models.diffusion.ddim import DDIMSampler\n",
        "from ldm.models.diffusion.plms import PLMSSampler\n",
        "import tensorflow as tf\n",
        "from dotmap import DotMap\n",
        "import ipywidgets as widgets\n",
        "from math import pi\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "import gc\n",
        "import io\n",
        "import math\n",
        "import sys\n",
        "import random\n",
        "from piq import brisque\n",
        "from itertools import product\n",
        "from IPython import display\n",
        "import lpips\n",
        "from PIL import Image, ImageOps\n",
        "import requests\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import functional as TF\n",
        "from numpy import nan\n",
        "from threading import Thread\n",
        "import time\n",
        "\n",
        "#sys.path.append('../CLIP')\n",
        "#Resizeright for better gradient when resizing\n",
        "#sys.path.append('../ResizeRight/')\n",
        "#sys.path.append('../cloob-training/')\n",
        "\n",
        "from resize_right import resize\n",
        "\n",
        "import clip\n",
        "#from cloob_training import model_pt, pretrained\n",
        "\n",
        "#pretrained.list_configs()\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twG4nxYCrI8F"
      },
      "outputs": [],
      "source": [
        "#@title Load the model\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "def load_model_from_config(config, ckpt, verbose=False, latent_diffusion_model=\"original\"):\n",
        "    print(f\"Loading model from {ckpt}\")\n",
        "    print(latent_diffusion_model)\n",
        "    model = instantiate_from_config(config.model)\n",
        "    sd = torch.load(ckpt, map_location=\"cuda\")[\"state_dict\"]\n",
        "    m, u = model.load_state_dict(sd, strict = False)\n",
        "    if(latent_diffusion_model == \"finetuned\"): \n",
        "      del sd\n",
        "      sd_finetune = torch.load(f\"{model_path}/finetuned_state_dict.pt\",map_location=\"cuda\")\n",
        "      m, u = model.model.load_state_dict(sd_finetune, strict = False)\n",
        "      model.model = model.model.half().eval().to(device)\n",
        "      del sd_finetune\n",
        " #   sd = pl_sd[\"state_dict\"]\n",
        "    \n",
        "    if len(m) > 0 and verbose:\n",
        "        print(\"missing keys:\")\n",
        "        print(m)\n",
        "    if len(u) > 0 and verbose:\n",
        "        print(\"unexpected keys:\")\n",
        "        print(u)\n",
        "\n",
        "    model.requires_grad_(False).half().eval().to('cuda')\n",
        "    return model\n",
        "\n",
        "config = OmegaConf.load(\"./latent-diffusion/configs/latent-diffusion/txt2img-1p4B-eval.yaml\")  # TODO: Optionally download from same location as ckpt and chnage this logic\n",
        "model = load_model_from_config(config, f\"{model_path}/latent_diffusion_txt2img_f8_large.ckpt\",False, latent_diffusion_model)  # TODO: check path\n",
        "model = model.half().eval().to(device)\n",
        "#if(latent_diffusion_model == \"finetuned\"):\n",
        "#  model.model = model.model.half().eval().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HY_7vvnPThzS"
      },
      "outputs": [],
      "source": [
        "#@title Load necessary functions\n",
        "def set_custom_schedules(schedule):\n",
        "  custom_schedules = []\n",
        "  for schedule_item in schedule:\n",
        "    if(isinstance(schedule_item,list)):\n",
        "      custom_schedules.append(np.arange(*schedule_item))\n",
        "    else:\n",
        "      custom_schedules.append(schedule_item)\n",
        "  \n",
        "  return custom_schedules\n",
        "\n",
        "def parse_prompt(prompt):\n",
        "    if prompt.startswith('http://') or prompt.startswith('https://') or prompt.startswith(\"E:\") or prompt.startswith(\"C:\") or prompt.startswith(\"D:\"):\n",
        "        vals = prompt.rsplit(':', 2)\n",
        "        vals = [vals[0] + ':' + vals[1], *vals[2:]]\n",
        "    else:\n",
        "        vals = prompt.rsplit(':', 1)\n",
        "    vals = vals + ['', '1'][len(vals):]\n",
        "    return vals[0], float(vals[1])\n",
        "\n",
        "\n",
        "class MakeCutouts(nn.Module):\n",
        "    def __init__(self, cut_size,\n",
        "                 Overview=4, \n",
        "                 WholeCrop = 0, WC_Allowance = 10, WC_Grey_P=0.2,\n",
        "                 InnerCrop = 0, IC_Size_Pow=0.5, IC_Grey_P = 0.2\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.Overview = Overview\n",
        "        self.WholeCrop= WholeCrop\n",
        "        self.WC_Allowance = WC_Allowance\n",
        "        self.WC_Grey_P = WC_Grey_P\n",
        "        self.InnerCrop = InnerCrop\n",
        "        self.IC_Size_Pow = IC_Size_Pow\n",
        "        self.IC_Grey_P = IC_Grey_P\n",
        "        self.augs = T.Compose([\n",
        "            #T.RandomHorizontalFlip(p=0.5),\n",
        "            T.Lambda(lambda x: x + torch.randn_like(x) * 0.01),\n",
        "            T.RandomAffine(degrees=0, \n",
        "                           translate=(0.05, 0.05), \n",
        "                           #scale=(0.9,0.95),\n",
        "                           fill=-1,  interpolation = T.InterpolationMode.BILINEAR, ),\n",
        "            T.Lambda(lambda x: x + torch.randn_like(x) * 0.01),\n",
        "            #T.RandomPerspective(p=1, interpolation = T.InterpolationMode.BILINEAR, fill=-1,distortion_scale=0.2),\n",
        "            T.Lambda(lambda x: x + torch.randn_like(x) * 0.01),\n",
        "            T.RandomGrayscale(p=0.1),\n",
        "            T.Lambda(lambda x: x + torch.randn_like(x) * 0.01),\n",
        "            T.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05),\n",
        "        ])\n",
        "\n",
        "    def forward(self, input):\n",
        "        gray = transforms.Grayscale(3)\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        l_size = max(sideX, sideY)\n",
        "        output_shape = [input.shape[0],3,self.cut_size,self.cut_size] \n",
        "        output_shape_2 = [input.shape[0],3,self.cut_size+2,self.cut_size+2]\n",
        "        pad_input = F.pad(input,((sideY-max_size)//2+round(max_size*0.055),(sideY-max_size)//2+round(max_size*0.055),(sideX-max_size)//2+round(max_size*0.055),(sideX-max_size)//2+round(max_size*0.055)), **padargs)\n",
        "        cutouts_list = []\n",
        "        \n",
        "        if self.Overview>0:\n",
        "            cutouts = []\n",
        "            cutout = resize(pad_input, out_shape=output_shape, antialiasing=True)\n",
        "            output_shape_all = list(output_shape)\n",
        "            output_shape_all[0]=self.Overview*input.shape[0]\n",
        "            pad_input = pad_input.repeat(input.shape[0],1,1,1)\n",
        "            cutout = resize(pad_input, out_shape=output_shape_all)\n",
        "            if aug: cutout=self.augs(cutout)\n",
        "            cutouts_list.append(cutout)\n",
        "            \n",
        "        if self.InnerCrop >0:\n",
        "            cutouts=[]\n",
        "            for i in range(self.InnerCrop):\n",
        "                size = int(torch.rand([])**self.IC_Size_Pow * (max_size - min_size) + min_size)\n",
        "                offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "                offsety = torch.randint(0, sideY - size + 1, ())\n",
        "                cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "                if i <= int(self.IC_Grey_P * self.InnerCrop):\n",
        "                    cutout = gray(cutout)\n",
        "                cutout = resize(cutout, out_shape=output_shape)\n",
        "                cutouts.append(cutout)\n",
        "            if cutout_debug:\n",
        "                TF.to_pil_image(cutouts[-1].add(1).div(2).clamp(0, 1).squeeze(0)).save(\"content/diff/cutouts/cutout_InnerCrop.jpg\",quality=99)\n",
        "            cutouts_tensor = torch.cat(cutouts)\n",
        "            cutouts=[]\n",
        "            cutouts_list.append(cutouts_tensor)\n",
        "        cutouts=torch.cat(cutouts_list)\n",
        "        return cutouts\n",
        "\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "\n",
        "def tv_loss(input):\n",
        "    \"\"\"L2 total variation loss, as in Mahendran et al.\"\"\"\n",
        "    input = F.pad(input, (0, 1, 0, 1), 'replicate')\n",
        "    x_diff = input[..., :-1, 1:] - input[..., :-1, :-1]\n",
        "    y_diff = input[..., 1:, :-1] - input[..., :-1, :-1]\n",
        "    return (x_diff**2 + y_diff**2).mean([1, 2, 3])\n",
        "\n",
        "\n",
        "def range_loss(input, range_min, range_max):\n",
        "    return (input - input.clamp(range_min,range_max)).pow(2).mean([1, 2, 3])\n",
        "\n",
        "def symmetric_loss(x):\n",
        "    w = x.shape[3]\n",
        "    diff = (x - torch.flip(x,[3])).square().mean().sqrt()/(x.shape[2]*x.shape[3]/1e4)\n",
        "    return(diff)\n",
        "\n",
        "def fetch(url_or_path):\n",
        "    \"\"\"Fetches a file from an HTTP or HTTPS url, or opens the local file.\"\"\"\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')\n",
        "\n",
        "\n",
        "def to_pil_image(x):\n",
        "    \"\"\"Converts from a tensor to a PIL image.\"\"\"\n",
        "    if x.ndim == 4:\n",
        "        assert x.shape[0] == 1\n",
        "        x = x[0]\n",
        "    if x.shape[0] == 1:\n",
        "        x = x[0]\n",
        "    return TF.to_pil_image((x.clamp(-1, 1) + 1) / 2)\n",
        "\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                 std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "def centralized_grad(x, use_gc=True, gc_conv_only=False):\n",
        "    if use_gc:\n",
        "        if gc_conv_only:\n",
        "            if len(list(x.size())) > 3:\n",
        "                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n",
        "        else:\n",
        "            if len(list(x.size())) > 1:\n",
        "                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n",
        "    return x\n",
        "\n",
        "def cond_fn(x, t):\n",
        "    t=1000-t\n",
        "    t=t[0]\n",
        "    with torch.enable_grad():\n",
        "        global clamp_start_, clamp_max\n",
        "        x = x.detach()\n",
        "        x = x.requires_grad_()\n",
        "        x_in = model.decode_first_stage(x)\n",
        "        display_handler(x_in,t,1,False)\n",
        "        n = x_in.shape[0]\n",
        "        clip_guidance_scale = clip_guidance_index[t]\n",
        "        make_cutouts = {}\n",
        "        #rx_in_grad = torch.zeros_like(x_in)\n",
        "        for i in clip_list:\n",
        "            make_cutouts[i] = MakeCutouts(clip_size[i],\n",
        "             Overview= cut_overview[t], \n",
        "             InnerCrop = cut_innercut[t], \n",
        "                                          IC_Size_Pow=cut_ic_pow, IC_Grey_P = cut_icgray_p[t]\n",
        "             )\n",
        "            cutn = cut_overview[t]+cut_innercut[t]\n",
        "        for j in range(cutn_batches):\n",
        "            losses=0\n",
        "            for i in clip_list:\n",
        "                clip_in = clip_normalize[i](make_cutouts[i](x_in.add(1).div(2)).to(\"cuda\"))\n",
        "                image_embeds = clip_model[i].encode_image(clip_in).float().unsqueeze(0).expand([target_embeds[i].shape[0],-1,-1])\n",
        "                target_embeds_temp = target_embeds[i]\n",
        "                if i == 'ViT-B-32--openai' and experimental_aesthetic_embeddings:\n",
        "                  aesthetic_embedding = torch.from_numpy(np.load(f'aesthetic-predictor/vit_b_32_embeddings/rating{experimental_aesthetic_embeddings_score}.npy')).to(device) \n",
        "                  aesthetic_query = target_embeds_temp + aesthetic_embedding * experimental_aesthetic_embeddings_weight\n",
        "                  target_embeds_temp = (aesthetic_query) / torch.linalg.norm(aesthetic_query)\n",
        "                if i == 'ViT-L-14--openai' and experimental_aesthetic_embeddings:\n",
        "                  aesthetic_embedding = torch.from_numpy(np.load(f'aesthetic-predictor/vit_l_14_embeddings/rating{experimental_aesthetic_embeddings_score}.npy')).to(device) \n",
        "                  aesthetic_query = target_embeds_temp + aesthetic_embedding * experimental_aesthetic_embeddings_weight\n",
        "                  target_embeds_temp = (aesthetic_query) / torch.linalg.norm(aesthetic_query)\n",
        "                target_embeds_temp = target_embeds_temp.unsqueeze(1).expand([-1,cutn*n,-1])          \n",
        "                dists = spherical_dist_loss(image_embeds, target_embeds_temp)\n",
        "                dists = dists.mean(1).mul(weights[i].squeeze()).mean()\n",
        "                losses+=dists*clip_guidance_scale * (2 if i in [\"ViT-L-14-336--openai\", \"RN50x64--openai\", \"ViT-B-32--laion2b_e16\"] else (.4 if \"cloob\" in i else 1))\n",
        "                if i == \"ViT-L-14-336--openai\" and aes_scale !=0:\n",
        "                    aes_loss = (aesthetic_model_336(F.normalize(image_embeds, dim=-1))).mean() \n",
        "                    losses -= aes_loss * aes_scale \n",
        "                if i == \"ViT-L-14--openai\" and aes_scale !=0:\n",
        "                    aes_loss = (aesthetic_model_224(F.normalize(image_embeds, dim=-1))).mean() \n",
        "                    losses -= aes_loss * aes_scale \n",
        "                if i == \"ViT-B-16--openai\" and aes_scale !=0:\n",
        "                    aes_loss = (aesthetic_model_16(F.normalize(image_embeds, dim=-1))).mean() \n",
        "                    losses -= aes_loss * aes_scale  \n",
        "                if i == \"ViT-B-32--openai\" and aes_scale !=0:\n",
        "                    aes_loss = (aesthetic_model_32(F.normalize(image_embeds, dim=-1))).mean()\n",
        "                    losses -= aes_loss * aes_scale\n",
        "            #x_in_grad += torch.autograd.grad(losses, x_in)[0] / cutn_batches / len(clip_list)\n",
        "                #losses += dists\n",
        "                #losses = losses / len(clip_list)                \n",
        "                #gc.collect()\n",
        " \n",
        "        tv_losses = tv_loss(x).sum() * tv_scales[0] +\\\n",
        "            tv_loss(F.interpolate(x, scale_factor= 1/2)).sum()* tv_scales[1] + \\\n",
        "            tv_loss(F.interpolate(x, scale_factor = 1/4)).sum()* tv_scales[2] + \\\n",
        "            tv_loss(F.interpolate(x, scale_factor = 1/8)).sum()* tv_scales[3] \n",
        "        range_scale= range_index[t]\n",
        "        range_losses = range_loss(x_in,RGB_min,RGB_max).sum() * range_scale\n",
        "        loss =  tv_losses  + range_losses + losses\n",
        "        #del losses\n",
        "        if symmetric_loss_scale != 0: loss +=  symmetric_loss(x_in) * symmetric_loss_scale\n",
        "        if init_image is not None and init_scale:\n",
        "            lpips_loss = (lpips_model(x_in, init) * init_scale).squeeze().mean()\n",
        "            #print(lpips_loss)\n",
        "            loss += lpips_loss\n",
        "        #loss_grad = torch.autograd.grad(loss, x_in, )[0]\n",
        "        #x_in_grad += loss_grad\n",
        "        #grad = -torch.autograd.grad(x_in, x, x_in_grad)[0]\n",
        "        loss.backward()\n",
        "        grad = -x.grad\n",
        "        grad = torch.nan_to_num(grad, nan=0.0, posinf=0, neginf=0)\n",
        "        if grad_center: grad = centralized_grad(grad, use_gc=True, gc_conv_only=False)\n",
        "        mag = grad.square().mean().sqrt()\n",
        "        if mag==0 or torch.isnan(mag):\n",
        "            print(\"ERROR\")\n",
        "            print(t)\n",
        "            return(grad)\n",
        "        if t>=0:\n",
        "            if active_function == \"softsign\":\n",
        "                grad = F.softsign(grad*grad_scale/mag)\n",
        "            if active_function == \"tanh\":\n",
        "                grad = (grad/mag*grad_scale).tanh()\n",
        "            if active_function==\"clamp\":\n",
        "                grad = grad.clamp(-mag*grad_scale*2,mag*grad_scale*2)\n",
        "        if grad.abs().max()>0:\n",
        "            grad=grad/grad.abs().max()*opt.mag_mul\n",
        "            magnitude = grad.square().mean().sqrt()\n",
        "        else:\n",
        "            return(grad)\n",
        "        clamp_max = clamp_index[t]\n",
        "        #print(magnitude, end = \"\\r\")\n",
        "        grad = grad* magnitude.clamp(max= clamp_max) /magnitude#0.2\n",
        "        grad = grad.detach()\n",
        "    return grad\n",
        "\n",
        "def null_fn(x_in):\n",
        "    return(torch.zeros_like(x_in))\n",
        "\n",
        "def display_handler(x,i,cadance = 5, decode = True):\n",
        "    global progress, image_grid, writer, img_tensor, im\n",
        "    img_tensor = x\n",
        "    if i%cadance==0:\n",
        "        if decode: \n",
        "            x = model.decode_first_stage(x)\n",
        "        grid = make_grid(torch.clamp((x+1.0)/2.0, min=0.0, max=1.0),round(x.shape[0]**0.5))\n",
        "        grid = 255. * rearrange(grid, 'c h w -> h w c').detach().cpu().numpy()\n",
        "        image_grid = grid.copy(order = \"C\") \n",
        "        with io.BytesIO() as output:\n",
        "            im = Image.fromarray(grid.astype(np.uint8))\n",
        "            im.save(output, format = \"PNG\")\n",
        "            progress.value = output.getvalue()\n",
        "            if generate_video:\n",
        "                im.save(p.stdin, 'PNG')\n",
        "\n",
        "\n",
        "            \n",
        "def cond_clamp(image,t): \n",
        "    #if t >=0:\n",
        "        #mag=image.square().mean().sqrt()\n",
        "        #mag = (mag*cc).clamp(1.6,100)\n",
        "        image = image.clamp(-cc, cc)\n",
        "        image = torch.nan_to_num(image, nan=0.0, posinf=cc, neginf=-cc)\n",
        "        return(image)\n",
        "\n",
        "def make_schedule(t_start, t_end, step_size=1):\n",
        "    schedule = []\n",
        "    par_schedule = []\n",
        "    t = t_start\n",
        "    while t > t_end:\n",
        "        schedule.append(t)\n",
        "        t -= step_size\n",
        "    schedule.append(t_end)\n",
        "    return np.array(schedule)\n",
        "\n",
        "lpips_model = lpips.LPIPS(net='vgg').to(device)\n",
        "\n",
        "def list_mul_to_array(list_mul):\n",
        "  i = 0\n",
        "  mul_count = 0\n",
        "  mul_string = ''\n",
        "  full_list = list_mul\n",
        "  full_list_len = len(full_list)\n",
        "  for item in full_list:\n",
        "    if(i == 0):\n",
        "      last_item = item\n",
        "    if(item == last_item):\n",
        "      mul_count+=1\n",
        "    if(item != last_item or full_list_len == i+1):\n",
        "      mul_string = mul_string + f' [{last_item}]*{mul_count} +'\n",
        "      mul_count=1\n",
        "    last_item = item\n",
        "    i+=1\n",
        "  return(mul_string[1:-2])\n",
        "\n",
        "def generate_settings_file(add_prompts=False, add_dimensions=False):\n",
        "  \n",
        "  if(add_prompts):\n",
        "    prompts = f'''\n",
        "    clip_prompts = {clip_prompts}\n",
        "    latent_prompts = {latent_prompts}\n",
        "    latent_negatives = {latent_negatives}\n",
        "    image_prompts = {image_prompts}\n",
        "    '''\n",
        "  else:\n",
        "    prompts = ''\n",
        "\n",
        "  if(add_dimensions):\n",
        "    dimensions = f'''width = {width}\n",
        "    height = {height}\n",
        "    '''\n",
        "  else:\n",
        "    dimensions = ''\n",
        "  settings = f'''\n",
        "    #This settings file can be loaded back to Latent Majesty Diffusion. If you like your setting consider sharing it to the settings library at https://github.com/multimodalart/MajestyDiffusion\n",
        "    [clip_list]\n",
        "    perceptors = {clip_load_list}\n",
        "    \n",
        "    [basic_settings]\n",
        "    #Perceptor things\n",
        "    {prompts}\n",
        "    {dimensions}\n",
        "    latent_diffusion_guidance_scale = {latent_diffusion_guidance_scale}\n",
        "    clip_guidance_scale = {clip_guidance_scale}\n",
        "    aesthetic_loss_scale = {aesthetic_loss_scale}\n",
        "    augment_cuts={augment_cuts}\n",
        "\n",
        "    #Init image settings\n",
        "    starting_timestep = {starting_timestep}\n",
        "    init_scale = {init_scale} \n",
        "    init_brightness = {init_brightness}\n",
        "    init_noise = {init_noise}\n",
        "\n",
        "    [advanced_settings]\n",
        "    #Add CLIP Guidance and all the flavors or just run normal Latent Diffusion\n",
        "    use_cond_fn = {use_cond_fn}\n",
        "\n",
        "    #Custom schedules for cuts. Check out the schedules documentation here\n",
        "    custom_schedule_setting = {custom_schedule_setting}\n",
        "\n",
        "    #Cut settings\n",
        "    clamp_index = {list_mul_to_array(clamp_index)}\n",
        "    cut_overview = {list_mul_to_array(cut_overview)}\n",
        "    cut_innercut = {list_mul_to_array(cut_innercut)}\n",
        "    cut_ic_pow = {cut_ic_pow}\n",
        "    cut_icgray_p = {list_mul_to_array(cut_icgray_p)}\n",
        "    cutn_batches = {cutn_batches}\n",
        "    range_index = {list_mul_to_array(range_index)}\n",
        "    active_function = \"{active_function}\"\n",
        "    tv_scales = {list_mul_to_array(tv_scales)}\n",
        "    latent_tv_loss = {latent_tv_loss}\n",
        "\n",
        "    #If you uncomment this line you can schedule the CLIP guidance across the steps. Otherwise the clip_guidance_scale will be used\n",
        "    clip_guidance_schedule = {list_mul_to_array(clip_guidance_index)}\n",
        "    \n",
        "    #Apply symmetric loss (force simmetry to your results)\n",
        "    symmetric_loss_scale = {symmetric_loss_scale} \n",
        "\n",
        "    #Latent Diffusion Advanced Settings\n",
        "    #Use when latent upscale to correct satuation problem\n",
        "    scale_div = {scale_div}\n",
        "    #Magnify grad before clamping by how many times\n",
        "    opt_mag_mul = {opt_mag_mul}\n",
        "    opt_ddim_eta = {opt_ddim_eta}\n",
        "    opt_eta_end = {opt_eta_end}\n",
        "    opt_temperature = {opt_temperature}\n",
        "\n",
        "    #Grad advanced settings\n",
        "    grad_center = {grad_center}\n",
        "    #Lower value result in more coherent and detailed result, higher value makes it focus on more dominent concept\n",
        "    grad_scale={grad_scale} \n",
        "\n",
        "    #Init image advanced settings\n",
        "    init_rotate={init_rotate}\n",
        "    mask_rotate={mask_rotate}\n",
        "    init_magnitude = {init_magnitude}\n",
        "\n",
        "    #More settings\n",
        "    RGB_min = {RGB_min}\n",
        "    RGB_max = {RGB_max}\n",
        "    #How to pad the image with cut_overview\n",
        "    padargs = {padargs} \n",
        "    flip_aug={flip_aug}\n",
        "    cc = {cc}\n",
        "    #Experimental aesthetic embeddings, work only with OpenAI ViT-B/32 and ViT-L/14\n",
        "    experimental_aesthetic_embeddings = {experimental_aesthetic_embeddings}\n",
        "    #How much you want this to influence your result\n",
        "    experimental_aesthetic_embeddings_weight = {experimental_aesthetic_embeddings_weight}\n",
        "    #9 are good aesthetic embeddings, 0 are bad ones\n",
        "    experimental_aesthetic_embeddings_score = {experimental_aesthetic_embeddings_score}\n",
        "    '''\n",
        "  return(settings)\n",
        "\n",
        "#Alstro's aesthetic model\n",
        "aesthetic_model_336 = torch.nn.Linear(768,1).cuda()\n",
        "aesthetic_model_336.load_state_dict(torch.load(f\"{model_path}/ava_vit_l_14_336_linear.pth\"))\n",
        "\n",
        "aesthetic_model_224 = torch.nn.Linear(768,1).cuda()\n",
        "aesthetic_model_224.load_state_dict(torch.load(f\"{model_path}/ava_vit_l_14_linear.pth\"))\n",
        "\n",
        "aesthetic_model_16 = torch.nn.Linear(512,1).cuda()\n",
        "aesthetic_model_16.load_state_dict(torch.load(f\"{model_path}/ava_vit_b_16_linear.pth\"))\n",
        "\n",
        "aesthetic_model_32 = torch.nn.Linear(512,1).cuda()\n",
        "aesthetic_model_32.load_state_dict(torch.load(f\"{model_path}/sa_0_4_vit_b_32_linear.pth\"))\n",
        "\n",
        "from ldm.modules.diffusionmodules.util import noise_like\n",
        "def do_run():\n",
        "  #  with torch.cuda.amp.autocast():\n",
        "        global progress,target_embeds, weights, zero_embed, init, scale_factor\n",
        "        scale_factor = 1\n",
        "        make_cutouts = {}\n",
        "        for i in clip_list:\n",
        "             make_cutouts[i] = MakeCutouts(clip_size[i],Overview=1)\n",
        "        target_embeds, weights ,zero_embed = {}, {}, {}\n",
        "        for i in clip_list:\n",
        "            target_embeds[i] = []\n",
        "            weights[i]=[]\n",
        "\n",
        "        for prompt in prompts:\n",
        "            txt, weight = parse_prompt(prompt)\n",
        "            for i in clip_list:\n",
        "                if \"cloob\" not in i:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        embeds = clip_model[i].encode_text(clip_tokenize[i](txt).to(device))\n",
        "                        target_embeds[i].append(embeds)\n",
        "                        weights[i].append(weight)\n",
        "                else:\n",
        "                        embeds = clip_model[i].encode_text(clip_tokenize[i](txt).to(device))\n",
        "                        target_embeds[i].append(embeds)\n",
        "                        weights[i].append(weight)\n",
        "\n",
        "        for prompt in image_prompts:\n",
        "            print(f\"processing{prompt}\",end=\"\\r\")\n",
        "            path, weight = parse_prompt(prompt)\n",
        "            img = Image.open(fetch(path)).convert('RGB')\n",
        "            img = TF.resize(img, min(opt.W, opt.H, *img.size), transforms.InterpolationMode.LANCZOS)\n",
        "            for i in clip_list:\n",
        "                if \"cloob\" not in i:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        batch = make_cutouts[i](TF.to_tensor(img).unsqueeze(0).to(device))\n",
        "                        embed = clip_model[i].encode_image(clip_normalize[i](batch))\n",
        "                        target_embeds[i].append(embed)\n",
        "                        weights[i].extend([weight])\n",
        "                else:\n",
        "                        batch = make_cutouts[i](TF.to_tensor(img).unsqueeze(0).to(device))\n",
        "                        embed = clip_model[i].encode_image(clip_normalize[i](batch))\n",
        "                        target_embeds[i].append(embed)\n",
        "                        weights[i].extend([weight])\n",
        "        if anti_jpg != 0:\n",
        "            target_embeds[\"ViT-B-32--openai\"].append(torch.tensor([np.load(f\"{model_path}/openimages_512x_png_embed224.npz\")['arr_0']-np.load(f\"{model_path}/imagenet_512x_jpg_embed224.npz\")['arr_0']], device = device))\n",
        "            weights[\"ViT-B-32--openai\"].append(anti_jpg)\n",
        "\n",
        "        for i in clip_list:\n",
        "            target_embeds[i] = torch.cat(target_embeds[i])\n",
        "            weights[i] = torch.tensor([weights[i]], device=device)\n",
        "        shape = [4, opt.H//8, opt.W//8]\n",
        "        init = None\n",
        "        mask = None\n",
        "        transform = T.GaussianBlur(kernel_size=3, sigma=0.4)\n",
        "        if init_image is not None:\n",
        "            init = Image.open(fetch(init_image)).convert('RGB')\n",
        "            init = TF.to_tensor(init).to(device).unsqueeze(0)\n",
        "            if init_rotate: init = torch.rot90(init, 1, [3,2]) \n",
        "            init = resize(init,out_shape = [opt.n_samples,3,opt.H, opt.W])\n",
        "            init = init.mul(2).sub(1).half()\n",
        "            init_encoded =  model.first_stage_model.encode(init).sample()* init_magnitude + init_brightness\n",
        "            init_encoded = init_encoded + noise_like(init_encoded.shape,device,False).mul(init_noise)\n",
        "        else:\n",
        "            init = None\n",
        "            init_encoded = None\n",
        "        if init_mask is not None:\n",
        "            mask = Image.open(fetch(init_mask)).convert('RGB')\n",
        "            mask = TF.to_tensor(mask).to(device).unsqueeze(0)\n",
        "            if mask_rotate: mask = torch.rot90(init, 1, [3,2]) \n",
        "            mask = resize(mask,out_shape = [opt.n_samples,1,opt.H//8, opt.W//8])\n",
        "            mask = transform(mask)\n",
        "            print(mask)\n",
        "\n",
        "\n",
        "        progress = widgets.Image(layout = widgets.Layout(max_width = \"400px\",max_height = \"512px\"))\n",
        "        display.display(progress)\n",
        "\n",
        "        if opt.plms:\n",
        "            sampler = PLMSSampler(model)\n",
        "        else:\n",
        "            sampler = DDIMSampler(model)\n",
        "\n",
        "        os.makedirs(opt.outdir, exist_ok=True)\n",
        "        outpath = opt.outdir\n",
        "\n",
        "        prompt = opt.prompt\n",
        "        sample_path = os.path.join(outpath, \"samples\")\n",
        "        os.makedirs(sample_path, exist_ok=True)\n",
        "        base_count = len(os.listdir(sample_path))\n",
        "\n",
        "        all_samples=list()\n",
        "        last_step_upscale = False\n",
        "        with torch.enable_grad():\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with model.ema_scope():\n",
        "                    uc = None\n",
        "                    if opt.scale != 1.0:\n",
        "                        uc = model.get_learned_conditioning(opt.n_samples * opt.uc).cuda()\n",
        "                    \n",
        "                    for n in trange(opt.n_iter, desc=\"Sampling\"):\n",
        "                        torch.cuda.empty_cache()\n",
        "                        gc.collect()\n",
        "                        c = model.get_learned_conditioning(opt.n_samples * prompt).cuda()\n",
        "                        if init_encoded is None:\n",
        "                            x_T = torch.randn([opt.n_samples,*shape], device=device)\n",
        "                        else:\n",
        "                            x_T = init_encoded\n",
        "                        last_step_uspcale_list = []\n",
        "                        \n",
        "                        for custom_schedule in custom_schedules:\n",
        "                            if type(custom_schedule) != type(\"\"):\n",
        "                                torch.cuda.empty_cache()\n",
        "                                gc.collect()\n",
        "                                last_step_upscale = False\n",
        "                                samples_ddim, _ = sampler.sample(S=opt.ddim_steps,\n",
        "                                                                 conditioning=c,\n",
        "                                                                 batch_size=opt.n_samples,\n",
        "                                                                 shape=shape,\n",
        "                                                                 custom_schedule = custom_schedule,\n",
        "                                                                 verbose=False,\n",
        "                                                                 unconditional_guidance_scale=opt.scale,\n",
        "                                                                 unconditional_conditioning=uc,\n",
        "                                                                 eta=opt.ddim_eta,\n",
        "                                                                 eta_end = opt.eta_end,\n",
        "                                                                 img_callback=None if use_cond_fn else display_handler,\n",
        "                                                                 cond_fn=cond_fn, #if use_cond_fn else None,\n",
        "                                                                 temperature = opt.temperature,\n",
        "                                                                 x_adjust_fn=cond_clamp,\n",
        "                                                                 x_T = x_T,\n",
        "                                                                 x0=x_T,\n",
        "                                                                 mask=mask\n",
        "                                                                )\n",
        "                                x_T = samples_ddim.clamp(-6,6)\n",
        "                            else:\n",
        "                                torch.cuda.empty_cache()\n",
        "                                gc.collect()\n",
        "                                method, scale_factor = custom_schedule.split(\":\")\n",
        "                                scale_factor = float(scale_factor)\n",
        "                                #clamp_index = np.array(clamp_index) * scale_factor\n",
        "                                if method == \"latent\":\n",
        "                                    x_T = resize(samples_ddim, scale_factors=scale_factor, antialiasing=True)*scale_div\n",
        "                                    x_T += noise_like(x_T.shape,device,False)*init_noise\n",
        "                                if method == \"gfpgan\":\n",
        "                                    last_step_upscale = True\n",
        "                                    temp_file_name = \"temp_\"+f\"{str(round(time.time()))}.png\"\n",
        "                                    temp_file = os.path.join(sample_path, temp_file_name)\n",
        "                                    im.save(temp_file, format = \"PNG\")\n",
        "                                    GFP_factor = 2 if scale_factor > 1 else 1\n",
        "                                    GFP_ver = 1.3 #if GFP_factor == 1 else 1.2\n",
        "                                    %cd GFPGAN\n",
        "                                    torch.cuda.empty_cache()\n",
        "                                    gc.collect()\n",
        "                                    !python inference_gfpgan.py -i $temp_file -o results -v $GFP_ver -s $GFP_factor\n",
        "                                    %cd ..\n",
        "                                    face_corrected = Image.open(fetch(f\"GFPGAN/results/restored_imgs/{temp_file_name}\"))\n",
        "                                    with io.BytesIO() as output:\n",
        "                                      face_corrected.save(output,format=\"PNG\")\n",
        "                                      progress.value = output.getvalue()\n",
        "                                    init = Image.open(fetch(f\"GFPGAN/results/restored_imgs/{temp_file_name}\")).convert('RGB')\n",
        "                                    init = TF.to_tensor(init).to(device).unsqueeze(0)\n",
        "                                    opt.H, opt.W = opt.H*scale_factor, opt.W*scale_factor\n",
        "                                    init = resize(init,out_shape = [opt.n_samples,3,opt.H, opt.W], antialiasing=True)\n",
        "                                    init = init.mul(2).sub(1).half()\n",
        "                                    x_T =  (model.first_stage_model.encode(init).sample()*init_magnitude)\n",
        "                                    x_T += noise_like(x_T.shape,device,False)*init_noise\n",
        "                                    x_T = x_T.clamp(-6,6)\n",
        "\n",
        "                        #last_step_uspcale_list.append(last_step_upscale)\n",
        "                        scale_factor = 1\n",
        "                        current_time = str(round(time.time()))\n",
        "                        if(last_step_upscale):\n",
        "                          latest_upscale = Image.open(fetch(f\"GFPGAN/results/restored_imgs/{temp_file_name}\")).convert('RGB')\n",
        "                          latest_upscale.save(os.path.join(outpath, f'{current_time}.png'), format = \"PNG\")\n",
        "                        else:\n",
        "                          Image.fromarray(image_grid.astype(np.uint8)).save(os.path.join(outpath, f'{current_time}.png'), format = \"PNG\")\n",
        "                        settings = generate_settings_file(add_prompts=True, add_dimensions=False)\n",
        "                        text_file = open(f\"{outpath}/{current_time}.cfg\", \"w\")\n",
        "                        text_file.write(settings)\n",
        "                        text_file.close()\n",
        "                        x_samples_ddim = model.decode_first_stage(samples_ddim)\n",
        "                        x_samples_ddim = torch.clamp((x_samples_ddim+1.0)/2.0, min=0.0, max=1.0)\n",
        "                        all_samples.append(x_samples_ddim)\n",
        "\n",
        "\n",
        "        if(len(all_samples) > 1):\n",
        "          # additionally, save as grid\n",
        "          grid = torch.stack(all_samples, 0)\n",
        "          grid = rearrange(grid, 'n b c h w -> (n b) c h w')\n",
        "          grid = make_grid(grid, nrow=opt.n_samples)\n",
        "\n",
        "          # to image\n",
        "          grid = 255. * rearrange(grid, 'c h w -> h w c').cpu().numpy()\n",
        "          Image.fromarray(grid.astype(np.uint8)).save(os.path.join(outpath, f'grid_{str(round(time.time()))}.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILHGCEla2Rrm"
      },
      "source": [
        "# Run!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpR9JhyCu5iq"
      },
      "source": [
        "#### Perceptors (Choose your CLIP and CLIP-like models) \n",
        "Be careful if you don't pay for Colab Pro selecting more CLIPs might make you go out of memory. If you do have Pro, try adding ViT-L14 to your mix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8K7l_E2JvLWC"
      },
      "outputs": [],
      "source": [
        "#@title Choose your perceptor models\n",
        "\n",
        "# suppress mmc warmup outputs\n",
        "import mmc.loaders\n",
        "clip_load_list = []\n",
        "#@markdown #### Open AI CLIP models\n",
        "ViT_B32 = False #@param {type:\"boolean\"}\n",
        "ViT_B16 = True #@param {type:\"boolean\"}\n",
        "ViT_L14 = False #@param {type:\"boolean\"}\n",
        "ViT_L14_336px = False #@param {type:\"boolean\"}\n",
        "#RN101 = False #@param {type:\"boolean\"}\n",
        "#RN50 = False #@param {type:\"boolean\"}\n",
        "RN50x4 = False #@param {type:\"boolean\"}\n",
        "RN50x16 = False #@param {type:\"boolean\"}\n",
        "RN50x64 = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #### OpenCLIP models\n",
        "ViT_B16_plus = False #@param {type: \"boolean\"}\n",
        "ViT_B32_laion2b = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown #### Multilangual CLIP models \n",
        "clip_farsi = False #@param {type: \"boolean\"}\n",
        "clip_korean = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown #### CLOOB models\n",
        "cloob_ViT_B16 = False #@param {type: \"boolean\"}\n",
        "\n",
        "# @markdown Load even more CLIP and CLIP-like models (from [Multi-Modal-Comparators](https://github.com/dmarx/Multi-Modal-Comparators))\n",
        "model1 = \"\" # @param [\"[clip - openai - RN50]\",\"[clip - openai - RN101]\",\"[clip - mlfoundations - RN50--yfcc15m]\",\"[clip - mlfoundations - RN50--cc12m]\",\"[clip - mlfoundations - RN50-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50-quickgelu--cc12m]\",\"[clip - mlfoundations - RN101--yfcc15m]\",\"[clip - mlfoundations - RN101-quickgelu--yfcc15m]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e32]\",\"[clip - sbert - ViT-B-32-multilingual-v1]\",\"[clip - facebookresearch - clip_small_25ep]\",\"[simclr - facebookresearch - simclr_small_25ep]\",\"[slip - facebookresearch - slip_small_25ep]\",\"[slip - facebookresearch - slip_small_50ep]\",\"[slip - facebookresearch - slip_small_100ep]\",\"[clip - facebookresearch - clip_base_25ep]\",\"[simclr - facebookresearch - simclr_base_25ep]\",\"[slip - facebookresearch - slip_base_25ep]\",\"[slip - facebookresearch - slip_base_50ep]\",\"[slip - facebookresearch - slip_base_100ep]\",\"[clip - facebookresearch - clip_large_25ep]\",\"[simclr - facebookresearch - simclr_large_25ep]\",\"[slip - facebookresearch - slip_large_25ep]\",\"[slip - facebookresearch - slip_large_50ep]\",\"[slip - facebookresearch - slip_large_100ep]\",\"[clip - facebookresearch - clip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc12m_35ep]\",\"[clip - facebookresearch - clip_base_cc12m_35ep]\"] {allow-input: true}\n",
        "model2 = \"\" # @param [\"[clip - openai - RN50]\",\"[clip - openai - RN101]\",\"[clip - mlfoundations - RN50--yfcc15m]\",\"[clip - mlfoundations - RN50--cc12m]\",\"[clip - mlfoundations - RN50-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50-quickgelu--cc12m]\",\"[clip - mlfoundations - RN101--yfcc15m]\",\"[clip - mlfoundations - RN101-quickgelu--yfcc15m]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e32]\",\"[clip - sbert - ViT-B-32-multilingual-v1]\",\"[clip - facebookresearch - clip_small_25ep]\",\"[simclr - facebookresearch - simclr_small_25ep]\",\"[slip - facebookresearch - slip_small_25ep]\",\"[slip - facebookresearch - slip_small_50ep]\",\"[slip - facebookresearch - slip_small_100ep]\",\"[clip - facebookresearch - clip_base_25ep]\",\"[simclr - facebookresearch - simclr_base_25ep]\",\"[slip - facebookresearch - slip_base_25ep]\",\"[slip - facebookresearch - slip_base_50ep]\",\"[slip - facebookresearch - slip_base_100ep]\",\"[clip - facebookresearch - clip_large_25ep]\",\"[simclr - facebookresearch - simclr_large_25ep]\",\"[slip - facebookresearch - slip_large_25ep]\",\"[slip - facebookresearch - slip_large_50ep]\",\"[slip - facebookresearch - slip_large_100ep]\",\"[clip - facebookresearch - clip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc12m_35ep]\",\"[clip - facebookresearch - clip_base_cc12m_35ep]\"] {allow-input: true}\n",
        "model3 = \"\" # @param [\"[clip - openai - RN50]\",\"[clip - openai - RN101]\",\"[clip - mlfoundations - RN50--yfcc15m]\",\"[clip - mlfoundations - RN50--cc12m]\",\"[clip - mlfoundations - RN50-quickgelu--yfcc15m]\",\"[clip - mlfoundations - RN50-quickgelu--cc12m]\",\"[clip - mlfoundations - RN101--yfcc15m]\",\"[clip - mlfoundations - RN101-quickgelu--yfcc15m]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_e32]\",\"[clip - mlfoundations - ViT-B-32-quickgelu--laion400m_avg]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e31]\",\"[clip - mlfoundations - ViT-B-16--laion400m_e32]\",\"[clip - sbert - ViT-B-32-multilingual-v1]\",\"[clip - facebookresearch - clip_small_25ep]\",\"[simclr - facebookresearch - simclr_small_25ep]\",\"[slip - facebookresearch - slip_small_25ep]\",\"[slip - facebookresearch - slip_small_50ep]\",\"[slip - facebookresearch - slip_small_100ep]\",\"[clip - facebookresearch - clip_base_25ep]\",\"[simclr - facebookresearch - simclr_base_25ep]\",\"[slip - facebookresearch - slip_base_25ep]\",\"[slip - facebookresearch - slip_base_50ep]\",\"[slip - facebookresearch - slip_base_100ep]\",\"[clip - facebookresearch - clip_large_25ep]\",\"[simclr - facebookresearch - simclr_large_25ep]\",\"[slip - facebookresearch - slip_large_25ep]\",\"[slip - facebookresearch - slip_large_50ep]\",\"[slip - facebookresearch - slip_large_100ep]\",\"[clip - facebookresearch - clip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc3m_40ep]\",\"[slip - facebookresearch - slip_base_cc12m_35ep]\",\"[clip - facebookresearch - clip_base_cc12m_35ep]\"] {allow-input: true}\n",
        "\n",
        "if ViT_B32: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-B-32--openai]\")\n",
        "if ViT_B16: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-B-16--openai]\")\n",
        "if ViT_L14: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-L-14--openai]\")\n",
        "if RN50x4: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - RN50x4--openai]\")\n",
        "if RN50x64: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - RN50x64--openai]\")\n",
        "if RN50x16: \n",
        "  clip_load_list.append(\"[clip - mlfoundations - RN50x16--openai]\")\n",
        "if ViT_L14_336px:\n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-L-14-336--openai]\")\n",
        "if ViT_B16_plus:\n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-B-16-plus-240--laion400m_e32]\")\n",
        "if ViT_B32_laion2b:\n",
        "  clip_load_list.append(\"[clip - mlfoundations - ViT-B-32--laion2b_e16]\")\n",
        "if clip_farsi:\n",
        "  clip_load_list.append(\"[clip - sajjjadayobi - clipfa]\")\n",
        "if clip_korean:\n",
        "  clip_load_list.append(\"[clip - navervision - kelip_ViT-B/32]\")\n",
        "if cloob_ViT_B16:\n",
        "  clip_load_list.append(\"[cloob - crowsonkb - cloob_laion_400m_vit_b_16_32_epochs]\")\n",
        "\n",
        "if model1:\n",
        "  clip_load_list.append(model1)\n",
        "if model2:\n",
        "  clip_load_list.append(model2)\n",
        "if model3:\n",
        "  clip_load_list.append(model3)\n",
        "\n",
        "\n",
        "i = 0\n",
        "from mmc.multimmc import MultiMMC\n",
        "from mmc.modalities import TEXT, IMAGE\n",
        "temp_perceptor = MultiMMC(TEXT, IMAGE)\n",
        "\n",
        "def get_mmc_models(clip_load_list):\n",
        "  mmc_models = []\n",
        "  for model_key in clip_load_list:\n",
        "      if not model_key:\n",
        "          continue\n",
        "      arch, pub, m_id = model_key[1:-1].split(' - ')\n",
        "      mmc_models.append({\n",
        "          'architecture':arch,\n",
        "          'publisher':pub,\n",
        "          'id':m_id,\n",
        "          })\n",
        "  return mmc_models\n",
        "mmc_models = get_mmc_models(clip_load_list)\n",
        "\n",
        "import mmc\n",
        "from mmc.registry import REGISTRY\n",
        "import mmc.loaders  # force trigger model registrations\n",
        "from mmc.mock.openai import MockOpenaiClip\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                 std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "\n",
        "def load_clip_models(mmc_models):\n",
        "  clip_model, clip_size, clip_tokenize, clip_normalize= {},{},{},{}\n",
        "  clip_list = []\n",
        "  for item in mmc_models:\n",
        "      print(\"Loaded \", item[\"id\"])\n",
        "      clip_list.append(item[\"id\"])\n",
        "      model_loaders = REGISTRY.find(**item)\n",
        "      for model_loader in model_loaders:\n",
        "          clip_model_loaded = model_loader.load()\n",
        "          clip_model[item[\"id\"]] = MockOpenaiClip(clip_model_loaded)\n",
        "          clip_size[item[\"id\"]] = clip_model[item[\"id\"]].visual.input_resolution\n",
        "          clip_tokenize[item[\"id\"]] = clip_model[item[\"id\"]].preprocess_text()\n",
        "          if(item[\"architecture\"] == 'cloob'):\n",
        "            clip_normalize[item[\"id\"]] = clip_model[item[\"id\"]].normalize\n",
        "          else:\n",
        "            clip_normalize[item[\"id\"]] = normalize\n",
        "  return clip_model, clip_size, clip_tokenize, clip_normalize, clip_list\n",
        "\n",
        "\n",
        "def full_clip_load(clip_load_list):\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  try:\n",
        "    del clip_model, clip_size, clip_tokenize, clip_normalize, clip_list\n",
        "  except:\n",
        "    pass\n",
        "  mmc_models = get_mmc_models(clip_load_list)\n",
        "  clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = load_clip_models(mmc_models)\n",
        "  return clip_model, clip_size, clip_tokenize, clip_normalize, clip_list\n",
        "\n",
        "clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Di3xFSXGWe"
      },
      "source": [
        "#### Advanced settings for the generation\n",
        "##### Access [our guide](https://multimodal.art/majesty-diffusion)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAALegoCXEbm"
      },
      "outputs": [],
      "source": [
        "opt = DotMap()\n",
        "\n",
        "#Change it to false to not use CLIP Guidance at all \n",
        "use_cond_fn = True\n",
        "\n",
        "#Custom cut schedules and super-resolution. Check out the guide on how to use it a https://multimodal.art/majestydiffusion\n",
        "custom_schedule_setting = [\n",
        " [200,1000,8],\n",
        " [50,200,5],\n",
        " #\"gfpgan:1.5\",\n",
        " #[50,200,5],\n",
        "]\n",
        "              \n",
        "#Cut settings\n",
        "clamp_index = [1]*1000 \n",
        "cut_overview = [8]*500 + [4]*500\n",
        "cut_innercut = [0]*500 + [4]*500\n",
        "cut_ic_pow = .1\n",
        "cut_icgray_p = [.1]*300+[0]*1000\n",
        "cutn_batches = 1\n",
        "range_index = [0]*300 + [0]*1000 \n",
        "active_function = \"softsign\" # function to manipulate the gradient - help things to stablize\n",
        "tv_scales = [1000]*1+[600]*3\n",
        "latent_tv_loss = True #Applies the TV Loss in the Latent space instead of pixel, improves generation quality\n",
        "\n",
        "#If you uncomment next line you can schedule the CLIP guidance across the steps. Otherwise the clip_guidance_scale basic setting will be used\n",
        "#clip_guidance_schedule = [10000]*300 + [500]*700\n",
        "\n",
        "symmetric_loss_scale = 0 #Apply symmetric loss\n",
        "\n",
        "#Latent Diffusion Advanced Settings\n",
        "scale_div = 0.5 # Use when latent upscale to correct satuation problem\n",
        "opt_mag_mul = 10 #Magnify grad before clamping\n",
        "#PLMS Currently not working, working on a fix\n",
        "#opt.plms = False #Won;=t work with clip guidance\n",
        "opt_ddim_eta, opt_eta_end = [1.4,1] # linear variation of eta\n",
        "opt_temperature = .975 \n",
        "\n",
        "#Grad advanced settings\n",
        "grad_center = False\n",
        "grad_scale= 0.5 #5 Lower value result in more coherent and detailed result, higher value makes it focus on more dominent concept\n",
        "anti_jpg = 0 #not working\n",
        "\n",
        "#Init image advanced settings\n",
        "init_rotate, mask_rotate=[False, False]\n",
        "init_magnitude = 0.15\n",
        "\n",
        "#More settings\n",
        "RGB_min, RGB_max = [-0.95,0.95]\n",
        "padargs = {\"mode\":\"constant\", \"value\": -1} #How to pad the image with cut_overview\n",
        "flip_aug=False\n",
        "cc = 60\n",
        "cutout_debug = False\n",
        "opt.outdir = outputs_path\n",
        "\n",
        "#Experimental aesthetic embeddings, work only with OpenAI ViT-B/32 and ViT-L/14\n",
        "experimental_aesthetic_embeddings = False\n",
        "#How much you want this to influence your result\n",
        "experimental_aesthetic_embeddings_weight = 0.5\n",
        "#9 are good aesthetic embeddings, 0 are bad ones\n",
        "experimental_aesthetic_embeddings_score = 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUu_pyTkuxiT"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo1tM270ryit"
      },
      "source": [
        "### Prompts\n",
        "The main prompt is the CLIP prompt. The Latent Prompts usually help with style and composition, you can turn them off by setting `latent_diffsion_guidance_scale=0` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRIC0eQervDN"
      },
      "outputs": [],
      "source": [
        "#Amp up your prompt game with prompt engineering, check out this guide: https://matthewmcateer.me/blog/clip-prompt-engineering/\n",
        "#Prompt for CLIP Guidance\n",
        "clip_prompts = [\"portrait of a princess in sanctuary, hyperrealistic painting trending on artstation\"]\n",
        "\n",
        "#Prompt for Latent Diffusion\n",
        "latent_prompts = [\"portrait of a princess in sanctuary, hyperrealistic painting trending on artstation\"]\n",
        "\n",
        "#Negative prompts for Latent Diffusion\n",
        "latent_negatives = [\"low quality image\"]\n",
        "\n",
        "image_prompts = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv8-gEvUsADL"
      },
      "source": [
        "### Diffuse!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fmafGmcyT1mZ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#@markdown ### Basic settings \n",
        "#@markdown We're still figuring out default settings. Experiment and <a href=\"https://github.com/multimodalart/majesty-diffusion\">share your settings with us</a>\n",
        "width =  256#@param{type: 'integer'}\n",
        "height =  256#@param{type: 'integer'}\n",
        "latent_diffusion_guidance_scale = 2 #@param {type:\"number\"}\n",
        "clip_guidance_scale = 5000 #@param{type: 'integer'}\n",
        "how_many_batches = 1 #@param{type: 'integer'}\n",
        "aesthetic_loss_scale = 200 #@param{type: 'integer'}\n",
        "augment_cuts=True #@param{type:'boolean'}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown  ### Init image settings\n",
        "#@markdown `init_image` requires the path of an image to use as init to the model\n",
        "init_image = None #@param{type: 'string'}\n",
        "if(init_image == '' or init_image == 'None'):\n",
        "  init_image = None\n",
        "#@markdown `starting_timestep`: How much noise do you want to add to your init image for it to then be difused by the model\n",
        "starting_timestep = 0.9 #@param{type: 'number'}\n",
        "#@markdown `init_mask` is a mask same width and height as the original image with the color black indicating where to inpaint\n",
        "init_mask = None #@param{type: 'string'}\n",
        "#@markdown `init_scale` controls how much the init image should influence the final result. Experiment with values around `1000`\n",
        "init_scale = 1000 #@param{type: 'integer'}\n",
        "init_brightness = 0.0 #@param{type: 'number'}\n",
        "#@markdown How much extra noise to add to the init image, independently from skipping timesteps (use it also if you are upscaling)\n",
        "init_noise = 0.6 #@param{type: 'number'}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### Custom saved settings\n",
        "#@markdown If you choose custom saved settings, the settings set by the preset overrule some of your choices. You can still modify the settings not in the preset. <a href=\"https://github.com/multimodalart/majesty-diffusion/tree/main/latent_settings_library\">Check what each preset modifies here</a>\n",
        "custom_settings = 'path/to/settings.cfg' #@param{type:'string'}\n",
        "settings_library = 'None (use settings defined above)' #@param [\"None (use settings defined above)\", \"default (optimized for colab free)\", \"dango233_princesses\", \"the_other_zippy_defaults\", \"makeitrad_defaults\"]\n",
        "if(settings_library != 'None (use settings defined above)'):\n",
        "  if(settings_library == 'default (optimized for colab free)'):\n",
        "    custom_settings = f'majesty-diffusion/latent_settings_library/default.cfg'\n",
        "  else:\n",
        "    custom_settings = f'majesty-diffusion/latent_settings_library/{settings_library}.cfg'\n",
        "\n",
        "global_var_scope = globals()\n",
        "if(custom_settings is not None and custom_settings != '' and custom_settings != 'path/to/settings.cfg'):\n",
        "  print('Loaded ', custom_settings)\n",
        "  try:\n",
        "    from configparser import ConfigParser\n",
        "  except ImportError:\n",
        "      from ConfigParser import ConfigParser\n",
        "  import configparser\n",
        "  \n",
        "  config = ConfigParser()\n",
        "  config.read(custom_settings)\n",
        "  #custom_settings_stream = fetch(custom_settings)\n",
        "  #Load CLIP models from config\n",
        "  if(config.has_section('clip_list')):\n",
        "    clip_incoming_list = config.items('clip_list')\n",
        "    clip_incoming_models = clip_incoming_list[0]\n",
        "    incoming_perceptors = eval(clip_incoming_models[1])\n",
        "    if((len(incoming_perceptors) != len(clip_load_list)) or not all(elem in incoming_perceptors for elem in clip_load_list)):\n",
        "      clip_load_list = incoming_perceptors\n",
        "      clip_model, clip_size, clip_tokenize, clip_normalize, clip_list = full_clip_load(clip_load_list)\n",
        "\n",
        "  #Load settings from config and replace variables\n",
        "  if(config.has_section('basic_settings')):\n",
        "    basic_settings = config.items('basic_settings')\n",
        "    for basic_setting in basic_settings:\n",
        "      global_var_scope[basic_setting[0]] = eval(basic_setting[1])\n",
        "  \n",
        "  if(config.has_section('advanced_settings')):\n",
        "    advanced_settings = config.items('advanced_settings')\n",
        "    for advanced_setting in advanced_settings:\n",
        "      global_var_scope[advanced_setting[0]] = eval(advanced_setting[1])\n",
        "\n",
        "if(((init_image is not None) and (init_image != 'None') and (init_image != '')) and starting_timestep != 1 and custom_schedule_setting[0][1] == 1000):\n",
        "  custom_schedule_setting[0] = [custom_schedule_setting[0][0], int(custom_schedule_setting[0][1]*starting_timestep), custom_schedule_setting[0][2]]\n",
        "\n",
        "prompts = clip_prompts\n",
        "opt.prompt = latent_prompts\n",
        "opt.uc = latent_negatives\n",
        "custom_schedules = set_custom_schedules(custom_schedule_setting)\n",
        "aes_scale = aesthetic_loss_scale\n",
        "try: \n",
        "  clip_guidance_schedule\n",
        "  clip_guidance_index = clip_guidance_schedule\n",
        "except:\n",
        "  clip_guidance_index = [clip_guidance_scale]*1000\n",
        "\n",
        "opt.W = (width//64)*64;\n",
        "opt.H = (height//64)*64;\n",
        "if opt.W != width or opt.H != height:\n",
        "    print(f'Changing output size to {opt.W}x{opt.H}. Dimensions must by multiples of 64.')\n",
        "\n",
        "opt.mag_mul = opt_mag_mul \n",
        "opt.ddim_eta = opt_ddim_eta\n",
        "opt.eta_end = opt_eta_end\n",
        "opt.temperature = opt_temperature\n",
        "opt.n_iter = how_many_batches\n",
        "opt.n_samples =  1\n",
        "#opt.W, opt.H = [width,height]\n",
        "opt.scale = latent_diffusion_guidance_scale\n",
        "aug = augment_cuts\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "generate_video = False\n",
        "if generate_video: \n",
        "    fps = 24\n",
        "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "do_run()\n",
        "if generate_video: \n",
        "    p.stdin.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cvUzcO9FeMT"
      },
      "source": [
        "### Save your own settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LGLUCX_UGqka"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ### Save current settings\n",
        "#@markdown If you would like to save your current settings, uncheck `skip_saving` and run this cell. You will get a `custom_settings.cfg` file you can reuse and share. If you like your results, send us a <a href=\"#\">pull request</a> to add your settings to the selectable library\n",
        "skip_saving = True #@param{type:'boolean'}\n",
        "if(not skip_saving):\n",
        "  data = generate_settings_file(add_prompts=False, add_dimensions=True)\n",
        "  text_file = open(\"custom_settings.cfg\", \"w\")\n",
        "  text_file.write(data)\n",
        "  text_file.close()\n",
        "  from google.colab import files\n",
        "  files.download('custom_settings.cfg')\n",
        "  print(\"Downloaded as custom_settings.cfg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzd-2mVMWHV0"
      },
      "source": [
        "### Biases acknowledgment\n",
        "Despite how impressive being able to turn text into image is, beware to the fact that this model may output content that reinforces or exarcbates societal biases. According to the <a href='https://arxiv.org/abs/2112.10752' target='_blank'>Latent Diffusion paper</a>:<i> \\\"Deep learning modules tend to reproduce or exacerbate biases that are already present in the data\\\"</i>. \n",
        "\n",
        "The model was trained on an unfiltered version the LAION-400M dataset, which scrapped non-curated image-text-pairs from the internet (the exception being the the removal of illegal content) and is meant to be used for research purposes, such as this one. <a href='https://laion.ai/laion-400-open-dataset/' target='_blank'>You can read more on LAION's website</a>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xEVSOJ4f0B21",
        "VpR9JhyCu5iq",
        "N_Di3xFSXGWe",
        "xEVSOJ4f0B21"
      ],
      "machine_shape": "hm",
      "name": "Latent Majesty Diffusion v1.3",
      "private_outputs": true,
      "provenance": []
    },
    "interpreter": {
      "hash": "b4a4bf4697e23b4c3b3e423ae13bbc2c4ea7ca320e4b464cb63699bfcb7913e4"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('majesty': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
